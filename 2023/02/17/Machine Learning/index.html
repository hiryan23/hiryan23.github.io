

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Ruiyang He">
  <meta name="keywords" content="">
  
    <meta name="description" content="本笔记整理自安泰经济与管理学院2022年春季学期课程BUSS2505-02机器学习，授课人是李成璋老师。">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习-课程笔记">
<meta property="og:url" content="http://hiryan23.github.io/2023/02/17/Machine%20Learning/index.html">
<meta property="og:site_name" content="Hiryan&#39;s Blog">
<meta property="og:description" content="本笔记整理自安泰经济与管理学院2022年春季学期课程BUSS2505-02机器学习，授课人是李成璋老师。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://hiryan23.github.io/pic/9538373a69fb3836595f01495607834.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/bfec802ec5619a7f6b5ef92fd832d31.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/6cf69ccc0b5e18ab05c080df1515205.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/110a43955525c0ad9a62c039eb3876a.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/dce728e8f2d0819688a148ebaf686f9.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/11af398aea2369112afe0fe46f5d255.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/379ac1b116f3c5612b0e6a1f3df25ea.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/b885ffb38cf90c077ad79abb079e005.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/57c1cdf60aceade4f79afcdcf5781c5.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/b9432d6edc99c82146c5ca340b6fd65.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/8c43075b2094ec2db8c526f1ea28d14.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/a99b5dbe4e510c276edb458034cea64.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/f70b694bdd89dce57b1ed3575e59c22.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/8918735b6e8c752e2d4ae0af01c4e03.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/7ba8a7a66050778027f6549fa41cb2a.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/10adcb662406252426c360458bf636b.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/8181efdc993f5c23481a08ae4ac524b.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/e4f39df5e0cf02295ed0adf94236c82.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/4010e1c4642202ac977ba16ffc9a0ee.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/b0f3730daa3d994524a12413137e863.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/1a58a26150be5c680563a0eb25d7b8a.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/30dc5adbbd599316a0cb17da5726c8c.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/f4eec853b3f60729c5dd34dc7b4acc9.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/0ad30f160f2e7ecab62f7354a1c4616.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/a28e0bebc2515f58f224263e5cbedf5.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/dd55e1c530692fa6810d9b314c15f84.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/6c170feb2750e49af1c23e63965b608.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/132f7b5bbcbb9caecf14d6a7f6bf2f0.png">
<meta property="og:image" content="http://hiryan23.github.io/2023/02/17/Machine%20Learning/8fce1beb900d9682237c079542b44f5.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/5192779dc145eba035b997cf1a76fcc.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/876fcd4c99289d7d14c2494c352de58.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/4cda0b999d6f3752153a5f48f5b45fa.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/8238a887080cb52105e2da7c8321fab.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/6360a7faf1d39affd8e0985f07daa4a.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/a07605c556f05131fcb0eed75e8fe92.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/c04750dc47e5320cec59791c2897602.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/4e3d1c319b8d2121651b340bb9e0379.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/28249e9b76fddb1d028bad646f5b33e.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/34a695cff223faf29380cb4cd036595.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/6a2e08f093e043bef56e9524d47d15f.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/2beb86993fa4ae74f0081ec91c2c703.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/ab20f3bcdac435adab7fbe44748781b.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/0dbd9f34a7dd01a3cf8fdff2267228b.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/3b345e6e23b44d137f2eef677b086a0.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/163ee69801c5fd90f0db8434f12c0a0.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/d6ac10786053cf27bd83808148d4005.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/99505909a8ce803cd2585640c29ea03.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/31005d52795dd6bf9d6ccb279d59ceb.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/f7eb0da81ed0871c9b951828e1eef00.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/44f6ee7c2003c9bfdc6952ad6a82bb8.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/7932e2084b642ada22ad4a78f912adf.png">
<meta property="og:image" content="http://hiryan23.github.io/2023/02/17/Machine%20Learning/cf8051b1925bef0c1100e19ec7ecdc2.png">
<meta property="og:image" content="http://hiryan23.github.io/2023/02/17/Machine%20Learning/46bc95f08fe1f0d64f8f9a4733f00b0.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/60f7ff4efd734ff604959c09c02b128.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/9bc96b20dd2d9a83b34e6770feefa63.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/cba0fc4f531383fa7eee44fe02e9de0.png">
<meta property="article:published_time" content="2023-02-17T15:12:03.271Z">
<meta property="article:modified_time" content="2023-09-16T11:39:41.744Z">
<meta property="article:author" content="Ruiyang He">
<meta property="article:tag" content="课程笔记">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://hiryan23.github.io/pic/9538373a69fb3836595f01495607834.png">
  
  
  
  <title>机器学习-课程笔记 - Hiryan&#39;s Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"hiryan23.github.io","root":"/","version":"1.9.5-a","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Hiryan&#39;s blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                <span>友链</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/bg/lungmen.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="机器学习-课程笔记"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-02-17 23:12" pubdate>
          2023年2月17日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          45k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          372 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">机器学习-课程笔记</h1>
            
            
              <div class="markdown-body">
                
                <blockquote>
<p><em>本笔记整理自安泰经济与管理学院2022年春季学期课程BUSS2505-02机器学习，授课人是李成璋老师。</em></p>
</blockquote>
<span id="more"></span>
<h2 id="Lecture1-Introduction"><a href="#Lecture1-Introduction" class="headerlink" title="Lecture1_Introduction"></a>Lecture1_Introduction</h2><h3 id="Applications"><a href="#Applications" class="headerlink" title="Applications"></a>Applications</h3><h4 id="Machine-Learning-is-all-around-us"><a href="#Machine-Learning-is-all-around-us" class="headerlink" title="Machine Learning is all around us"></a>Machine Learning is all around us</h4><ul>
<li>Game AI<ul>
<li>Deep blue, IBM</li>
<li>AlphaGo, Deep Mind</li>
<li>Deepstack, CMU &amp; Facebook AI</li>
</ul>
</li>
<li>Robot<ul>
<li>SpotMini, BostonDynamics</li>
<li>Big Dog</li>
</ul>
</li>
<li>Image recognition</li>
<li>Self-driving car</li>
<li>Medical Diagnosis</li>
<li>Applications of ML in business settings</li>
<li>Customer segmentation</li>
<li>Applications in Finance</li>
<li>Credit lending &amp; Fraud detection</li>
<li>Personalized recommendation</li>
<li>Dynamic pricing<ul>
<li>Rue La La</li>
</ul>
</li>
<li>Order dispatch for ride-sharing platforms<ul>
<li>DiDi</li>
</ul>
</li>
</ul>
<h4 id="Economical-impact-of-Machine-Learning"><a href="#Economical-impact-of-Machine-Learning" class="headerlink" title="Economical impact of Machine Learning"></a>Economical impact of Machine Learning</h4><ul>
<li>By 2035, AI could double annual global economic growth rates (Accenture)</li>
<li>Global GDP may increase by up to 14% (the equivalent of US$15.7 trillion) by 2030 as a result of the accelerating development and take-up of AI (PwC)</li>
</ul>
<h4 id="Trends-of-Machine-Learning"><a href="#Trends-of-Machine-Learning" class="headerlink" title="Trends of Machine Learning"></a>Trends of Machine Learning</h4><p><img src="/pic/9538373a69fb3836595f01495607834.png" srcset="/img/loading.gif" lazyload alt="Trends of ML"></p>
<h3 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h3><h4 id="What-is-Machine-Learning"><a href="#What-is-Machine-Learning" class="headerlink" title="What is Machine Learning?"></a>What is Machine Learning?</h4><ul>
<li>Field of study that gives computers the ability to learn without being explicitly programmed. - Arthur Samuel, 1959</li>
<li>A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E. - Tom Mitchell, 1997</li>
</ul>
<h4 id="Programming-vs-Machine-Learning"><a href="#Programming-vs-Machine-Learning" class="headerlink" title="Programming vs Machine Learning"></a>Programming vs Machine Learning</h4><p><img src="/pic/bfec802ec5619a7f6b5ef92fd832d31.png" srcset="/img/loading.gif" lazyload alt="Programming vs ML"></p>
<h4 id="Brief-History-of-Machine-Learning"><a href="#Brief-History-of-Machine-Learning" class="headerlink" title="Brief History of Machine Learning"></a>Brief History of Machine Learning</h4><ol>
<li>Connectionism, 1950s<ul>
<li>Perception, F. Rosenblatt</li>
</ul>
</li>
<li>Checker game, Arthur Samuel, 1959<ul>
<li>The term Machine Learning is coined.</li>
</ul>
</li>
<li>Symbolism, 1970-1980s<ul>
<li>Decision tree</li>
<li>ID3, Quinlan</li>
<li>Classification and Regression Tree (CART)</li>
</ul>
</li>
<li>Connectionism, 1980-1990s<ul>
<li>Back-Propagation</li>
<li>for Multi-layer Neural Networks</li>
</ul>
</li>
<li>Statistical Learning, 1990s<ul>
<li>Support vector machine</li>
<li>Kernel methods</li>
</ul>
</li>
<li>Connectionism, 2000s<ul>
<li>Deep Learning</li>
</ul>
</li>
</ol>
<h3 id="Categories"><a href="#Categories" class="headerlink" title="Categories"></a>Categories</h3><p>Categories of Machine Learning<br><img src="/pic/6cf69ccc0b5e18ab05c080df1515205.png" srcset="/img/loading.gif" lazyload alt="Categories of ML"></p>
<h4 id="Supervised-Learning"><a href="#Supervised-Learning" class="headerlink" title="Supervised Learning"></a>Supervised Learning</h4><p><img src="/pic/110a43955525c0ad9a62c039eb3876a.png" srcset="/img/loading.gif" lazyload alt="SL"></p>
<ul>
<li>Aims to <strong>predict on unknown data</strong> using models trained by labeled data</li>
<li>Learning a function that maps the <strong>feature (attribute)</strong> to <strong>label (response)</strong></li>
<li>Classification vs Regression<ul>
<li>Both utilize the training set (known data) to make predictions</li>
<li>The output of classification is categorical (<strong>discrete</strong>) while the output of regression is numerical (<strong>continuous</strong>)</li>
</ul>
</li>
</ul>
<h5 id="Process-of-Supervised-Learning"><a href="#Process-of-Supervised-Learning" class="headerlink" title="Process of Supervised Learning"></a>Process of Supervised Learning</h5><ol>
<li>Split data into training &amp; test sets</li>
<li>Train a model</li>
<li>Make predictions on testing set</li>
<li>Compare predicted and true labels</li>
</ol>
<h4 id="Unsupervised-Learning"><a href="#Unsupervised-Learning" class="headerlink" title="Unsupervised Learning"></a>Unsupervised Learning</h4><p><img src="/pic/dce728e8f2d0819688a148ebaf686f9.png" srcset="/img/loading.gif" lazyload alt="UL"></p>
<p>Discover the structure and pattern within the unlabeled data.</p>
<ul>
<li>Market Segmentation</li>
<li>Social Network Analysis</li>
</ul>
<h4 id="Some-Machine-Learning-algorithms"><a href="#Some-Machine-Learning-algorithms" class="headerlink" title="Some Machine Learning algorithms"></a>Some Machine Learning algorithms</h4><p><img src="/pic/11af398aea2369112afe0fe46f5d255.png" srcset="/img/loading.gif" lazyload alt="ML algorithms"></p>
<h2 id="Lecture2-MathForML"><a href="#Lecture2-MathForML" class="headerlink" title="Lecture2_MathForML"></a>Lecture2_MathForML</h2><h4 id="Notations"><a href="#Notations" class="headerlink" title="Notations"></a>Notations</h4><ul>
<li>$a \in A$ : $a$ is a member of set A</li>
<li>$||\pmb{v}||$ : the norm of vector $\pmb{v}$</li>
<li>$\pmb{x},\pmb{y},\pmb{z}$ : vector (lower case, bold)</li>
<li>$\pmb{A},\pmb{B}$ : matrix (upper case, bold)</li>
<li>$X$ : random variable (upper case)</li>
<li>$x$ : realizaton of random variable (lower case)</li>
<li>$y= f(\pmb{x})$ : function with muitiple inputs</li>
</ul>
<h3 id="Probability-amp-Statistics"><a href="#Probability-amp-Statistics" class="headerlink" title="Probability &amp; Statistics"></a>Probability &amp; Statistics</h3><h4 id="Sample-space-Omega"><a href="#Sample-space-Omega" class="headerlink" title="Sample space($\Omega$)"></a>Sample space($\Omega$)</h4><p>Set of all possible outcomes of an experiment</p>
<h4 id="Event-E"><a href="#Event-E" class="headerlink" title="Event($E$)"></a>Event($E$)</h4><p>Any subset of outcomes contained in the sample space</p>
<h4 id="Event-space-mathcal-F"><a href="#Event-space-mathcal-F" class="headerlink" title="Event space($\mathcal F$)"></a>Event space($\mathcal F$)</h4><p>The set of all possible events</p>
<h4 id="Axioms-of-probability"><a href="#Axioms-of-probability" class="headerlink" title="Axioms of probability"></a>Axioms of probability</h4><p>The <em>probabililty distribution</em> P is a function that satisfies the following</p>
<ol>
<li>$0 \leq P(E) \leq 1$ for any $E \in \mathcal F$ (Non-negativity)</li>
<li>$P(\Omega)=1$ </li>
<li>$P(E_1 \cup E_2)=P(E_1)+P(E_2)$ if $E_1$ and $E_2$ mutually exclusive events (Additivity)</li>
</ol>
<h4 id="Random-variable-RV"><a href="#Random-variable-RV" class="headerlink" title="Random variable (RV)"></a>Random variable (RV)</h4><p>mapping from sample space to real numbers</p>
<ul>
<li>Probability distribution specifies the probability of observing every possible value of a random variable</li>
<li>Discrete RV has a countable set of possible values: Bernoulli, Poisson, …</li>
<li>Continuous RV can take infinitely many possible values: Uniform, Normal, Exponential, …</li>
</ul>
<h4 id="Probability-distribution"><a href="#Probability-distribution" class="headerlink" title="Probability distribution"></a>Probability distribution</h4><p>Cumulative distribution function (CDF)</p>
<script type="math/tex; mode=display">F_X(x)=P(X \leq x)</script><p>Discrete random variable: probability mass function $p_X(x)$</p>
<script type="math/tex; mode=display">p_X(x)=P(X=x)</script><p>Continuous random variable: probability density function $f_X(x)$</p>
<script type="math/tex; mode=display">f_X(x) = \cfrac{\text{d}F_X(x)}{\text{d}x}</script><h4 id="Joint-distribution"><a href="#Joint-distribution" class="headerlink" title="Joint distribution"></a>Joint distribution</h4><p>Consider two random variables $X$ and $Y$ , the <em>joint cumulative distribution function</em> is defined as</p>
<script type="math/tex; mode=display">F_{XY}(x,y)=P(X \leq x,Y \leq y)</script><p>The joint probability mass function of two discrete variables $X$ , $Y$</p>
<script type="math/tex; mode=display">p_{X,Y}(x,y)=P(X=x,Y=y)</script><p>The joint probability density function of two continuous variables $X$ , $Y$</p>
<script type="math/tex; mode=display">f_{X,Y}(x,y)=\cfrac{\partial^2 F_{XY}(x,y)}{\partial x \partial y}</script><h4 id="Conditional-probability"><a href="#Conditional-probability" class="headerlink" title="Conditional probability"></a>Conditional probability</h4><p>The conditional probability of $X$ given $Y=y$ is defined as, </p>
<script type="math/tex; mode=display">P(X=x|Y=y)=\cfrac{P(X=x,Y=y)}{P(Y=y)}</script><h4 id="Product-rule"><a href="#Product-rule" class="headerlink" title="Product rule"></a>Product rule</h4><script type="math/tex; mode=display">P(X=x,Y=y)=P(X=x|Y=y)P(Y=y)=P(Y=y|X=x)P(X=x)</script><h4 id="Bayes’-rule"><a href="#Bayes’-rule" class="headerlink" title="Bayes’ rule"></a>Bayes’ rule</h4><script type="math/tex; mode=display">P(Y=y|X=x)=\cfrac{P(X=x|Y=y)\cdot P(Y=y)}{P(X=x)}</script><ul>
<li>Application: SPAM email case<ul>
<li>y: labels (SPAM/normal)</li>
<li>x: frequency of keywords    </li>
</ul>
</li>
</ul>
<h4 id="Marginal-probability"><a href="#Marginal-probability" class="headerlink" title="Marginal probability"></a>Marginal probability</h4><p>The probability of event that will occur regardless of conditional events</p>
<script type="math/tex; mode=display">
\begin{align}
P(X=x) &= \sum_{y \in \mathcal{y}}P(X=x,Y=y) \\
       &= \sum_{y \in \mathcal{y}}P(X=x|Y=y)P(Y=y)
\end{align}</script><h4 id="Independence"><a href="#Independence" class="headerlink" title="Independence"></a>Independence</h4><p>Consider two events $A$ and $B$ , they are <em>independent</em>  if</p>
<script type="math/tex; mode=display">
P(X=x,Y=y)=P(X=x) \cdot P(Y=y)</script><p>In addition, (if they are independent: )</p>
<script type="math/tex; mode=display">
P(X=x)= \cfrac{P(X=x,Y=y)}{P(Y=y)}=P(X=x | Y=y)</script><h4 id="Expectation"><a href="#Expectation" class="headerlink" title="Expectation"></a>Expectation</h4><p>Expectation (expected value) of a random variable $X$ is computed as</p>
<ul>
<li><u>Discrete RV</u> <script type="math/tex">\mathbb{E} [x] = \sum_x x \cdot p(x)</script></li>
<li><u>Continuous RV</u> <script type="math/tex">\mathbb{E}[X]=\int_x x \cdot f(x) \cdot \text{d} x</script></li>
<li>Expectation of functions <script type="math/tex">\mathbb{E}[h(X)] = \int_x h(x) \cdot  f(x) \cdot \text{d}x</script></li>
<li>Other properties: <script type="math/tex">\begin{align}
\mathbb{E}[aX+b]&=a\mathbb{E}[X]+b \\
\mathbb{E}[X+Y]&=\mathbb{E}[X]+\mathbb{E}[Y]\\
\mathbb E[XY]&=\mathbb E[X]\mathbb E[Y],\ \text{if\ X\ and\ Y\ are uncoorrelated}
\end{align}</script></li>
</ul>
<h4 id="Conditional-expectation"><a href="#Conditional-expectation" class="headerlink" title="Conditional expectation"></a>Conditional expectation</h4><p>The conditional expectation of $X$ with respect to $Y$ is the function</p>
<script type="math/tex; mode=display">\mathbb{E}[X|Y=y]</script><p>Discrete random variable</p>
<script type="math/tex; mode=display">\mathbb{E}[X|Y=y]= \sum_x x\cdot P(X=x|Y=y)</script><p>Continuous random variable</p>
<script type="math/tex; mode=display">\mathbb{E}[X|Y=y]=\int_x x f_{X|Y}(x|y) \text{d}x</script><h5 id="Law-of-total-expectation"><a href="#Law-of-total-expectation" class="headerlink" title="Law of total expectation"></a>Law of total expectation</h5><script type="math/tex; mode=display">\mathbb{E}[X] = \mathbb{E}[\mathbb{E}[X|Y]]</script><h4 id="Variance"><a href="#Variance" class="headerlink" title="Variance"></a>Variance</h4><p>The squared deviation of $X$ from its mean</p>
<script type="math/tex; mode=display">\text{Var}[X]=\mathbb{E}[(X-\mathbb{E}[X])^2]=\mathbb{E}[X^2]=\mathbb{E}[X]^2</script><ul>
<li>Standard variation <script type="math/tex">\sigma = \sqrt{\text{Var}[X]}</script></li>
<li>Other properties <script type="math/tex">\begin{align}
\text{Var}[aX+b]&=a^2 \cdot \text{Var}[x] \\
\text{Var}[X+Y]&=\text{Var}[X]+\text{Var}[Y]\ \text{if X,Y are uncorrelated}
\end{align}</script></li>
</ul>
<h4 id="Covariance"><a href="#Covariance" class="headerlink" title="Covariance"></a>Covariance</h4><script type="math/tex; mode=display">\text{Cov}(X_1,X_2)=\mathbb{E}[(X_1-\mathbb{E}[X_1])(X_2-\mathbb{E}[X_2])]</script><h4 id="Estimation-of-Parameters"><a href="#Estimation-of-Parameters" class="headerlink" title="Estimation of Parameters"></a>Estimation of Parameters</h4><ul>
<li>Suppose we have random variables $X_1, X_2, \cdots, X_n$ and corresponding observations $x_1, x_2, \cdots, x_n$</li>
<li>We select a parametric model and fit the parameters of the model to the data.</li>
<li>How do we choose the values of the parameters $\theta$ ?</li>
</ul>
<h5 id="Maximum-Likelihood-Estimation-MLE"><a href="#Maximum-Likelihood-Estimation-MLE" class="headerlink" title="Maximum Likelihood Estimation (MLE)"></a>Maximum Likelihood Estimation (MLE)</h5><p>Which $\theta$ makes the observations $x_1,x_2,\cdots,x_n$ most likely?</p>
<ul>
<li>Maximize the likelihood of the observed data <script type="math/tex">\hat{\theta}_{MLE}=\text{arg}\max_\theta \mathcal{L}(\theta)=\text{arg}\max_\theta p(x_1,x_2,\cdots,x_n|\theta)</script></li>
<li>Assume that $x_1,x_2, \cdots,x_n$ are i.i.d., we have <script type="math/tex">\mathcal{L}(\theta)=\prod_{i=1}^n p(x_i|\theta)</script></li>
<li>Take the logarithmic on both sides, we obtain the log-likelihood <script type="math/tex">\log \mathcal{L}(\theta)= \sum_{i=1}^n \log p(x_i|\theta)</script><h6 id="Example-of-MLE"><a href="#Example-of-MLE" class="headerlink" title="Example of MLE"></a>Example of MLE</h6></li>
<li>Imagine a bowl contains a large number of red and white balls. The proportion of the red balls, denoted by $\theta$ , is unknown.</li>
<li>Now we sample balls from this bowl with replacement for $n$ times and observe $x$ red balls out of $n$ balls.</li>
<li>Likelihood function:<script type="math/tex">\begin{align}
L(\theta)=L(x;\theta)=\binom{n}{x}\theta^x(1-\theta)^{n-x} \\
\log L(\theta) = x\log \theta+(n-x)\log(1-\theta) \\
\cfrac{\partial \log L(\theta)}{\partial \theta} = 0 \Rightarrow \hat\theta_{MLE} = \cfrac{x}{n}
\end{align}</script></li>
</ul>
<h5 id="Maximum-A-Posteriori-Estimation-MAP"><a href="#Maximum-A-Posteriori-Estimation-MAP" class="headerlink" title="Maximum A Posteriori Estimation (MAP)"></a>Maximum A Posteriori Estimation (MAP)</h5><p>Which $\theta$ maximizes the posterior $p(\theta | x_1,x_2,\cdots,x_n)$ given the prior $p(\theta)$ ?</p>
<ul>
<li>We assume that the parameter is a random variable, and we specify a prior distribution $p(\theta)$</li>
<li>By Bayes’ rule, we compute the posterior of the parameter <script type="math/tex">p(\theta | x_1,x_2,\cdots,x_n) \propto p(\theta)p(x_1,x_2,\cdots,x_n|\theta)</script></li>
<li>Estimate parameter $\theta$ by maximizing the posterior <script type="math/tex">\hat\theta_{MAP}=\text{arg}\max_\theta p(\theta)p(x_1,x_2,\cdots,x_n|\theta)</script></li>
<li>We take the logarithmic of the posterior, <script type="math/tex">\hat\theta_{MAP}=\text{arg}\max_\theta \log p(\theta)+\sum_{i=1}^n \log p(x_i|\theta)</script><br><em>: MAP: balance MLE and prior knowledge</em></li>
</ul>
<h6 id="Example-of-MAP"><a href="#Example-of-MAP" class="headerlink" title="Example of MAP"></a>Example of MAP</h6><ul>
<li>Imagine a bowl contains a large number of red and white balls. The proportion of the red balls, denoted by $\theta$ , is unknown, but with a Beta prior, $P(\theta) =\cfrac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1}$</li>
<li>Now we sample balls from this bowl with replacement for $n$ times and observe $x$ red balls out of $n$ balls.</li>
<li>The posterior function: <script type="math/tex">\begin{align}
p(x|\theta)p(\theta) &= \binom{n}{x}\theta^x(1-\theta)^{n-x}\cfrac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1} \\
\log p(x|\theta)p(\theta) &= (x+\alpha-1)\log \theta +(n-x+\beta -1)\log(1-\theta) \\
\hat\theta_{MAP}&=\cfrac{x+\alpha-1}{n+\alpha+\beta-2}
\end{align}</script></li>
</ul>
<h3 id="Linear-Algebra"><a href="#Linear-Algebra" class="headerlink" title="Linear Algebra"></a>Linear Algebra</h3><h4 id="Vector"><a href="#Vector" class="headerlink" title="Vector"></a>Vector</h4><ul>
<li>A one-dimension array of $n$ values, denoted by $\pmb{x}$ (lower case, bold)</li>
<li>$x_i$ is the $i$-th element of $\pmb{x}$ <script type="math/tex">\pmb{x}=(x_1,x_2,\cdots,x_n)^T= \begin{bmatrix}x_1\\ x_2\\ \vdots \\ x_n \end{bmatrix}</script></li>
</ul>
<h4 id="Matrix"><a href="#Matrix" class="headerlink" title="Matrix"></a>Matrix</h4><ul>
<li>A two-dimension array of $m \times n$ values, denoted by $\pmb{A}$ (upper case, bold)</li>
<li>$m$ is the number of row vector, $n$ is the number of column vectors</li>
<li>$a_{ij}$ is the entry in $i$-th row and $j$-th column <script type="math/tex">\pmb{A}=\begin{bmatrix} a_{11} &\cdots &a_{1n} \\ \vdots &\ddots &\vdots \\ a_{m1} &\cdots &a_{mn} \end{bmatrix}</script></li>
</ul>
<h4 id="Vector-algorithmic"><a href="#Vector-algorithmic" class="headerlink" title="Vector algorithmic"></a>Vector algorithmic</h4><ul>
<li>Scalar multiplication of a vector <script type="math/tex">\pmb{y}=a\pmb{x}=(ax_1,ax_2,\cdots,ax_n)^T</script></li>
<li>Dot product of the vectors $\pmb{x},\pmb{y} \in \mathbb{R}^n$ <script type="math/tex">\pmb{x}^T\pmb{y} = [x_1,x_2,\cdots, x_n]\begin{bmatrix}y_1\\ y_2\\ \vdots\\ y_n\end{bmatrix}=\sum_{i=1}^n x_iy_i \in \mathbb{R}</script></li>
<li>Outer product of the vectors $\pmb{x} \in \mathbb{R}^m, \pmb{y} \in \mathbb{R}^n$ <script type="math/tex">\pmb{x}\pmb{y}^T=\begin{bmatrix}x_1\\ x_2\\ \vdots x_m\end{bmatrix}[y_1,y_2,\cdots,y_n]=\begin{bmatrix}x_1y_1 &\cdots &x_1y_n\\ \vdots &\ddots &\vdots\\ x_my_1 &\cdots &x_my_n\end{bmatrix}</script></li>
</ul>
<h4 id="Vector-norm"><a href="#Vector-norm" class="headerlink" title="Vector norm"></a>Vector norm</h4><p>A norm $||\cdot||$ is a function that satisfies</p>
<ul>
<li>$||\pmb{x}|| \geq 0$ with equality if and only if $\pmb{x}=\pmb{0}$</li>
<li>$||\pmb{x}+\pmb{y}|| \leq ||\pmb{x}|| + ||\pmb{y}||$</li>
<li>$||a\pmb{x}||=|a|||\pmb{x}||$</li>
<li>$\pmb{x}^T\pmb{y}=||\pmb{x}||_2||\pmb{y}||_2\cos(\theta)$</li>
<li>$l_1$ norm $||\pmb{x}||_1=\displaystyle\sum_{i=1}^n|x_i|$</li>
<li>$l_2$ norm $||\pmb{x}||_2=\left(\displaystyle\sum_{i=1}^n|x_i|^2\right)^{\frac{1}{2}}$ </li>
</ul>
<h4 id="Matrix-arithmetric"><a href="#Matrix-arithmetric" class="headerlink" title="Matrix arithmetric"></a>Matrix arithmetric</h4><ul>
<li>Addition of matrices $\pmb{A},\pmb{B} \in \mathbb{R}^{m\times n}$ <script type="math/tex">\pmb{C}=\pmb{A}+\textcolor{red}{\pmb{B}}=\begin{bmatrix} a_{11}+\textcolor{red}{b_{11}} &\cdots &a_{1n}+\textcolor{red}{b_{1n}}\\ \vdots &\ddots &\vdots\\ a_{m1}+\textcolor{red}{b_{m1}} &\cdots &a_{mn}+\textcolor{red}{b_{mn}} \end{bmatrix}</script></li>
<li>Scalar multiplication of a matrix <script type="math/tex">\pmb{B}=\textcolor{red}{d}\cdot \pmb{A}=\begin{bmatrix}\textcolor{red}{d}\cdot a_{11} &\cdots &\textcolor{red}{d}\cdot a_{1n}\\ \vdots &\ddots &\vdots\\ \textcolor{red}{d}\cdot a_{m1} &\cdots &\textcolor{red}{d}\cdot a_{mn}\end{bmatrix}</script></li>
<li>Multiplication of matrices $\pmb{A} \in \mathbb{R}^{m \times n}$ and $\pmb{B} \in \mathbb{R}^{n\times p}$ <script type="math/tex">\pmb{A}\pmb{B}=\pmb{C} \in \mathbb{R}^{m\times p},\ \ \ \ c_{ij}=\sum_{k=1}^na_{ik}b_{kj}</script></li>
<li>Matrix multiplication is <em>associative</em>: $\pmb{A}(\pmb{B}\pmb{C})=(\pmb{AB})\pmb{C}$ </li>
<li>Matrix multiplication is <em>distributive</em>: $\pmb A (\pmb B+\pmb C)=\pmb{AB}+\pmb{AC}$</li>
<li>Matrix multiplication is <em>NOT communicative</em>: $\pmb{AB} \neq \pmb{BA}$</li>
</ul>
<h4 id="Transpose"><a href="#Transpose" class="headerlink" title="Transpose"></a>Transpose</h4><p>Given a matrix $\pmb A \in \mathbb R^{m\times n}$ , its transpose, written by $\pmb A^T \in \mathbb R^{n\times m}$ , is given by <script type="math/tex">(\pmb A^T)_{ij}=(\pmb A)_{ji}</script><br>Some properties</p>
<ul>
<li>$(\pmb{AB})^T=\pmb B^T\pmb A^T$</li>
<li>$(\pmb A^T)^T=\pmb A$</li>
<li>$(\pmb A+\pmb B)^T=\pmb A^T+\pmb B^T$</li>
</ul>
<h4 id="Symmetric-matrix"><a href="#Symmetric-matrix" class="headerlink" title="Symmetric matrix"></a>Symmetric matrix</h4><p>A square matrix is <em>symmetric</em> if $\pmb A =\pmb A^T$.</p>
<h4 id="Inverse-of-a-matrix"><a href="#Inverse-of-a-matrix" class="headerlink" title="Inverse of a matrix"></a>Inverse of a matrix</h4><p>For a matrix $\pmb A\in \mathbb R^{n\times n}$ , if there exists a square matrix $\pmb B \in \mathbb R^{n\times n}$ such that <script type="math/tex">\pmb{BA}=\pmb{AB}=\pmb I</script><br>where $\pmb I$ is the $n$-by-$n$ <em>identity matrix</em>, then $\pmb B$ is the <em>inverse</em> of $\pmb A$.</p>
<ul>
<li>The inverse of $\pmb A$ is denoted by $\pmb A^{-1}$ </li>
<li>A matrix is <em>invertible</em> if it is not <em>singular</em>.</li>
</ul>
<p><u>Solving a linear system</u><br>If $\pmb A$ is square nonsingular matrix, then the solution to the linear system $\pmb{AX}=\pmb b$ is given by <script type="math/tex">\pmb x=\pmb A^{-1}\pmb b</script></p>
<h4 id="Semidefinite-matrices"><a href="#Semidefinite-matrices" class="headerlink" title="Semidefinite matrices"></a>Semidefinite matrices</h4><p>A symmetric matrix $\pmb A \in \mathbb S^{n\times n}$ is </p>
<ul>
<li><em>positive semidefinite</em> if $\pmb x^T \pmb{Ax} \geq 0$ for any $\pmb x \in \mathbb R^n$ and $\pmb x \neq \pmb 0$ , denoted by $\pmb A \succcurlyeq 0$ ;</li>
<li><em>positive definite</em> if $\pmb x^T \pmb{Ax} \textgreater 0$ for any $\pmb x \in \mathbb R^n$ and $\pmb x \neq 0$ , denoted by $\pmb A \succ 0$ ;</li>
<li>negative semidefinite if $-\pmb A$ is positive semidefinite;</li>
<li>negative definite if $-\pmb A$ is positive definite;</li>
<li>indefinite if it is neither positive nor negative definite.</li>
</ul>
<h4 id="Back-to-Probability-amp-Statistics"><a href="#Back-to-Probability-amp-Statistics" class="headerlink" title="Back to Probability &amp; Statistics"></a>Back to Probability &amp; Statistics</h4><h5 id="Random-vector"><a href="#Random-vector" class="headerlink" title="Random vector"></a>Random vector</h5><p>A vector of random variables $X_1,X_2,\cdots,X_n$, denoted by $\pmb X=[X_1,X_2,\cdots,X_n]^T$ </p>
<ul>
<li>$\mathbb E[X]=[\mathbb E[X_1],\mathbb E[X_2],\cdots,\mathbb E[X_n]]^T$</li>
</ul>
<h5 id="Covariance-matrix"><a href="#Covariance-matrix" class="headerlink" title="Covariance matrix"></a>Covariance matrix</h5><script type="math/tex; mode=display">\Sigma = \begin{bmatrix} \text{Cov}[X_1,X_1] &\cdots &\text{Cov}[X_1,X_n]\\ \vdots &\ddots &\vdots\\ \text{Cov}[X_n,X_1] &\cdots &\text{Cov}[X_n,X_n]\end{bmatrix}=\mathbb E[(\pmb X -\mathbb E[X])(\pmb X-\mathbb E[\pmb X])^T]</script><h4 id="Matrix-calculus"><a href="#Matrix-calculus" class="headerlink" title="Matrix calculus"></a>Matrix calculus</h4><p>Consider a function $f:\mathbb R^n \rightarrow \mathbb R$ , the <em>gradient</em> of $f$ is defined as a vector of partial derivatives <script type="math/tex">\nabla f(\pmb x)=\begin{bmatrix}\cfrac{\partial f(\pmb x)}{\partial x_1}\\ \cfrac{\partial f(\pmb x)}{\partial x_2}\\ \vdots\\ \cfrac{\partial f(\pmb x)}{\partial x_n}\end{bmatrix}</script><br>“direction and rate of fastest <strong>increase</strong>“</p>
<ul>
<li>The direction of fastest increase of the function</li>
<li>The magnitude is the rate of increase</li>
</ul>
<p>Consider a function $f: \mathbb R^n \rightarrow \mathbb R$, the <em>Hessian</em> of $f$ is defined as <script type="math/tex">\nabla^2f(\pmb x)=\begin{bmatrix}\cfrac{\partial^2f(\pmb x)}{\partial x_1^2} &\cdots &\cfrac{\partial^2f(\pmb x)}{\partial x_1\partial x_n}\\ \vdots &\ddots &\vdots\\ \cfrac{\partial^2f(\pmb x)}{\partial x_n\partial x_1} &\cdots &\cfrac{\partial^2f(\pmb x)}{\partial x_n^2}\end{bmatrix}</script></p>
<ul>
<li>Hessian is symmetric when $f$ is twice differentiable. <script type="math/tex">\cfrac{\partial^2 f(\pmb x)}{\partial x_i\partial x_j}=\cfrac{\partial^2f(\pmb x)}{\partial x_j\partial x_i}</script><h3 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h3></li>
</ul>
<h4 id="What-is-optimization"><a href="#What-is-optimization" class="headerlink" title="What is optimization?"></a>What is optimization?</h4><p>Finding the minimizer of a function subject to constraints:</p>
<script type="math/tex; mode=display">\begin{align}
\text{minimize}_{\pmb x} \ \ \ \ &f(\pmb x) \\
s.t.\ \ \ \ &f_i(\pmb x)\leq 0,i=1,2,\cdots, k;\\
&h_j(\pmb x)=0,j=1,2,\cdots,l.
\end{align}</script><ul>
<li>Mean-variance analysis</li>
<li>Transportation problems</li>
<li>Facility location</li>
<li>Linear regression</li>
<li>Logistic regression</li>
<li>Support vector machine</li>
<li>Neural networks</li>
</ul>
<h4 id="Local-minima-and-global-minima"><a href="#Local-minima-and-global-minima" class="headerlink" title="Local minima and global minima"></a>Local minima and global minima</h4><ul>
<li>Local minima is the solution that optimal within a neighboring set</li>
<li>Global minima is the optimal solution among all possible solutions<br><img src="/pic/379ac1b116f3c5612b0e6a1f3df25ea.png" srcset="/img/loading.gif" lazyload alt=""></li>
</ul>
<h4 id="Convex-set"><a href="#Convex-set" class="headerlink" title="Convex set"></a>Convex set</h4><p>A set $C\in \mathbb R^n$ is <em>convex</em> if for $\pmb x,\pmb y\in C$ and any $\alpha\in [0,1]$, <script type="math/tex">\alpha \pmb x+(1-\alpha)\pmb y \in C</script><img src="/pic/b885ffb38cf90c077ad79abb079e005.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>Examples: $\mathbb R^n$ , norm ball {$\pmb x: ||\pmb x|| \leq r$} for a given $r$ , intersection of convex sets</p>
<h4 id="Convex-Concave-function"><a href="#Convex-Concave-function" class="headerlink" title="Convex (Concave) function"></a>Convex (Concave) function</h4><p>A function $f:\mathbb R^n \rightarrow \mathbb R$ is convex (concave) if for $\pmb x,\pmb y \in \text{dom}(f)$ and any $\alpha \in [0,1]$ , <script type="math/tex">f(\alpha \pmb x+(1-\alpha)\pmb y)\leq(\geq) \alpha f(\pmb x)+(1-\alpha)f(\pmb y)</script><img src="/pic/57c1cdf60aceade4f79afcdcf5781c5.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h4 id="First-order-convexity-condition"><a href="#First-order-convexity-condition" class="headerlink" title="First-order convexity condition"></a>First-order convexity condition</h4><p>Suppose a function $f:\mathbb R^n \rightarrow \mathbb R$ is differentiable. Then $f$ is convex if and only if for all $\pmb x,\pmb y \in \text{dom}(f)$ <script type="math/tex">f(\pmb y) \geq f(\pmb x) + \nabla f(\pmb x)^T(\pmb y-\pmb x)</script><img src="/pic/b9432d6edc99c82146c5ca340b6fd65.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h4 id="Second-order-convexity-condition"><a href="#Second-order-convexity-condition" class="headerlink" title="Second-order convexity condition"></a>Second-order convexity condition</h4><p>Suppose a function $f:\mathbb R^n \rightarrow \mathbb R$ is twice differentiable. Then $f$ is convex if and only if for all $\pmb x \in \text{dom}(f)$ <script type="math/tex">\nabla^2f(\pmb x)\succcurlyeq 0</script><img src="/pic/8c43075b2094ec2db8c526f1ea28d14.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h4 id="Examples-of-convex-functions"><a href="#Examples-of-convex-functions" class="headerlink" title="Examples of convex functions"></a>Examples of convex functions</h4><ul>
<li>Exponential function: $e^{ax}$</li>
<li>Logarithmic function: $\log(x)$ is concave</li>
<li>Affine function: $\pmb a^T\pmb x+b$ is a convex and concave</li>
<li>Least square loss: $||\pmb y-\pmb{X\beta}||_2^2$</li>
<li>$f_1(x)$ is convex for $x\in \text{dom}(f_1)$ and $f_2(x)$ is convex for $x\in \text{dom}(f_2)$ , then $f_1+f_2$ is convex for $x\in \text{dom}(f_1) \cap \text{dom}(f_2)$ </li>
</ul>
<h4 id="Convex-optimization-problem"><a href="#Convex-optimization-problem" class="headerlink" title="Convex optimization problem"></a>Convex optimization problem</h4><p>An optimization problem is convex if its objective is a convex function, the inequality constraints $f_j$ are convex, and the equality constraints $h_j$ are affine. </p>
<script type="math/tex; mode=display">\begin{align}
\text{minimize}_{\pmb x} \ \ \ \ &f(\pmb x)\\
s.t. \ \ \ \ &f_i(\pmb x)\leq 0,i=1,2,\cdots,k; \\
&h_j(\pmb x)=0,j=1,2,\cdots,l.
\end{align}</script><h4 id="It’s-nice-to-be-convex"><a href="#It’s-nice-to-be-convex" class="headerlink" title="It’s nice to be convex!"></a>It’s nice to be convex!</h4><ul>
<li>$\nabla f(\pmb x)=0$ if and only if $\pmb x$ is a global minimizer of $f(\pmb x)$ .</li>
<li>If $\pmb x$ is a local minimizer of a convex optimization problem, it is a global minimizer.</li>
</ul>
<h4 id="Optimization-methods"><a href="#Optimization-methods" class="headerlink" title="Optimization methods"></a>Optimization methods</h4><ul>
<li>Gradient descent</li>
<li>Newton’s method</li>
<li>Coordinate descent</li>
<li>Lagrangian method</li>
</ul>
<h2 id="Lecture3-BasicInML"><a href="#Lecture3-BasicInML" class="headerlink" title="Lecture3_BasicInML"></a>Lecture3_BasicInML</h2><h3 id="Generalization-ability-泛化能力"><a href="#Generalization-ability-泛化能力" class="headerlink" title="Generalization ability (泛化能力)"></a>Generalization ability (泛化能力)</h3><ul>
<li>A model’s ability to generalize to new data</li>
<li>If the model is trained too well, it can fit perfectly the random fluctuatioins or noise in the training data but it will fail to predict accurately on new data<br><img src="/pic/a99b5dbe4e510c276edb458034cea64.png" srcset="/img/loading.gif" lazyload alt=""></li>
</ul>
<h4 id="Underfitting-and-overfitting"><a href="#Underfitting-and-overfitting" class="headerlink" title="Underfitting and overfitting"></a>Underfitting and overfitting</h4><ul>
<li><p>Underfitting (欠拟合) occurs when a statistical model or machine learning algorithm cannot capture the underlying trend of the data.<br><img src="/pic/f70b694bdd89dce57b1ed3575e59c22.png" srcset="/img/loading.gif" lazyload alt=""></p>
</li>
<li><p>Overfitting (过拟合) occurs when a statistical model describes random error or noise instead of the underlying relationship.<br><img src="/pic/8918735b6e8c752e2d4ae0af01c4e03.png" srcset="/img/loading.gif" lazyload alt=""></p>
</li>
</ul>
<h4 id="Basic-terms"><a href="#Basic-terms" class="headerlink" title="Basic terms"></a>Basic terms</h4><ul>
<li>A sample is denoted by $(\pmb x_i,y_i)$ where $\pmb x_i$ is the attribute (feature) vector and $y_i$ is the label (response).</li>
<li>A list of $m$ samples is a dataset, denoted by $D$ .<script type="math/tex">D=\{(\pmb x_i,y_i):i=1,2,\cdots,m\}</script><ul>
<li>Training set, denoted by $S$ , is used to train the model</li>
<li>Test set, denoted by $T$ , is used to evaluate the performance of the model</li>
</ul>
</li>
<li>A mapping from the attribute space (特征空间) $\mathcal X$ to the label space (标签空间) $\mathcal Y$ , denoted by $f$ , is called a hypothesis (假设).<script type="math/tex">f:\mathcal X \rightarrow \mathcal Y</script></li>
<li>The set of all possible hypotheses is called hypothesis space (假设空间), denoted by $F$ .<script type="math/tex">F=\{f_1,f_2,\cdots\}</script></li>
</ul>
<h4 id="Loss-function"><a href="#Loss-function" class="headerlink" title="Loss function"></a>Loss function</h4><ul>
<li>Suppose $\hat f(\pmb x)$ is obtained using the training set $S$ </li>
<li>For an unknown sample $(\pmb x_0,y_0)$ , the error between the prediction $\hat f(\pmb x_0)$ and the observed value $y_0$ is measured by the loss function (损失函数) <script type="math/tex">L(\hat f(\pmb x_0),y_0)</script></li>
<li>Examples<ul>
<li>$L(\hat f(\pmb x),y)=\mathbb I(\hat f(\pmb x)\neq y)$ (binary classification)</li>
<li>$L(\hat f(\pmb x),y)=(\hat f(\pmb x)-y)^2$ (regression)</li>
</ul>
</li>
</ul>
<h4 id="Generalization-error"><a href="#Generalization-error" class="headerlink" title="Generalization error"></a>Generalization error</h4><h5 id="Generalization-error-泛化误差"><a href="#Generalization-error-泛化误差" class="headerlink" title="Generalization error (泛化误差)"></a>Generalization error (泛化误差)</h5><script type="math/tex; mode=display">R(f)=\mathbb E [L(f(\pmb x),y)]</script><ul>
<li>The expectation is taken over the joint distribution of $(\pmb x ,y)$ </li>
</ul>
<h5 id="Test-error-测试误差"><a href="#Test-error-测试误差" class="headerlink" title="Test error (测试误差)"></a>Test error (测试误差)</h5><ul>
<li>Given a set of test samples $T=\{(\pmb x_i,y_i):i=1,2,\cdots,n\}$ , the test error is given by <script type="math/tex">\hat R_T(f)=\cfrac{1}{n}\sum_{i=1}^n L(f(\pmb x_i),y_i)</script></li>
</ul>
<h5 id="Training-error-训练误差"><a href="#Training-error-训练误差" class="headerlink" title="Training error (训练误差)"></a>Training error (训练误差)</h5><ul>
<li>Given a set of training samples $S=\{(\pmb x_i,y_i):i=1,2,\cdots,m\}$ , the training error is given by <script type="math/tex">\hat R_S(f)=\cfrac{1}{m}\sum_{i=1}^mL(f(\pmb x_i),y_i)</script><h5 id="Learning-objective"><a href="#Learning-objective" class="headerlink" title="Learning objective"></a>Learning objective</h5></li>
<li>Select a hypothesis $f\in F$ with the smallest <em>generalization error</em>. <script type="math/tex">\min_{f\in F}R(f)=\min_{f\in F}\mathbb E[L(f(\pmb x),y)]</script></li>
<li>However, the true distribution of $(\pmb x,y)$ is usually unknown in practice.</li>
<li>We obtain the hypothesis by minimizing the <em>training error</em> with the training set $S=\{(\pmb x_i,y_i):i=1,2,\cdots,m\}$ ,<script type="math/tex">\min_{f\in F}\hat R_S(f)=\min_{f\in F}\cfrac{1}{m}\sum_{i=1}^m L(f(\pmb x_i),y_i)</script></li>
</ul>
<h5 id="Training-error-vs-test-error"><a href="#Training-error-vs-test-error" class="headerlink" title="Training error vs test error"></a>Training error vs test error</h5><p><img src="/pic/7ba8a7a66050778027f6549fa41cb2a.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h3 id="Performance-metrics"><a href="#Performance-metrics" class="headerlink" title="Performance metrics"></a>Performance metrics</h3><h4 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h4><h5 id="Performance-metrics-for-classification"><a href="#Performance-metrics-for-classification" class="headerlink" title="Performance metrics for classification"></a>Performance metrics for classification</h5><ul>
<li>Consider a binary classifier $\mathcal Y =\{-,+\}$<br><img src="/pic/10adcb662406252426c360458bf636b.png" srcset="/img/loading.gif" lazyload alt=""></li>
</ul>
<h5 id="Confusion-matrix"><a href="#Confusion-matrix" class="headerlink" title="Confusion matrix"></a>Confusion matrix</h5><p><img src="/pic/8181efdc993f5c23481a08ae4ac524b.png" srcset="/img/loading.gif" lazyload alt=""></p>
<ul>
<li>True Positive (真正例) - we predicted “+” and the true class is “+”</li>
<li>True Negative (真反例) - we predicted “-“ and the true class is “-“</li>
<li>False Positive (假正例) - we predicted “+” and the true class is “-“</li>
<li>False Negative (假反例) - we predicted “-“ and the true class is “+”</li>
</ul>
<h5 id="Accuracy"><a href="#Accuracy" class="headerlink" title="Accuracy"></a>Accuracy</h5><script type="math/tex; mode=display">\text{Accuracy} = \cfrac{TP+TN}{TP+FN+FP+TN}=\cfrac{\text{Correct predictions}}{\text{Total data points}}</script><ul>
<li>The relationship with the misclassification error rate (分类错误率), <script type="math/tex">\text{Accuracy}=1-\cfrac{1}{m}\sum_{i=1}^m\mathbb I (f(\pmb x_i\neq y_i))</script><h6 id="Limitation-of-Accuracy"><a href="#Limitation-of-Accuracy" class="headerlink" title="Limitation of Accuracy"></a>Limitation of Accuracy</h6></li>
<li>A predictive model may have high accuracy, but be useless.<ul>
<li>Suppose the positive class is only a tiny portion of the observed data. For example, only 1% of patients has true cancer while other 99% of patients don’t have any cancers.</li>
<li>Consider a “stupid” model that always predicts “no cancer”, what is the accuracy?</li>
</ul>
</li>
</ul>
<h5 id="Precision-查准率"><a href="#Precision-查准率" class="headerlink" title="Precision(查准率)"></a>Precision(查准率)</h5><script type="math/tex; mode=display">\text{Precision}=\cfrac{TP}{TP+FP}=\cfrac{\text{Correctly predicted positive}}{\text{All predicted positive}}</script><h5 id="Recall-查全率"><a href="#Recall-查全率" class="headerlink" title="Recall(查全率)"></a>Recall(查全率)</h5><script type="math/tex; mode=display">\text{Recall}=\cfrac{TP}{TP+FN}=\cfrac{\text{Correctly predicted positive}}{\text{All real positive}}</script><ul>
<li>Which one is worse, False Positive or False Negative?</li>
<li>It depends!<ul>
<li>Medical Diagnosis - False Negative</li>
<li>Span Detection - False Positive</li>
</ul>
</li>
</ul>
<h5 id="F-1-score"><a href="#F-1-score" class="headerlink" title="$F_1$ score"></a>$F_1$ score</h5><ul>
<li>How to compare precision/recall and decide which algorithm is better?</li>
<li><p>$F_1$ score: a combined measure <script type="math/tex">F_1=2\cfrac{\text{Precision}\times\text{Recall}}{\text{Precision}+\text{Recall}}</script></p>
</li>
<li><p>Which metric to use?</p>
</li>
<li>Accuracy<ul>
<li>The class distribution is balanced</li>
<li>FP and FN costs are similar</li>
</ul>
</li>
<li>$F_1$ score<ul>
<li>The class distribution is unbalanced</li>
<li>FP and FN costs may be different</li>
</ul>
</li>
<li>Recall<ul>
<li>The cost of FN is much higher than that of FP</li>
<li>e.g. rather get healthy people labeled as sick over leaving a infected person labeled healthy</li>
</ul>
</li>
<li>Precision<ul>
<li>The cost of FP is much higher than that of FN</li>
<li>e.g. rather have some span emails in inbox than some regular emails in your spam box</li>
</ul>
</li>
</ul>
<h4 id="Regression"><a href="#Regression" class="headerlink" title="Regression"></a>Regression</h4><h5 id="Performance-metrics-for-regression"><a href="#Performance-metrics-for-regression" class="headerlink" title="Performance metrics for regression"></a>Performance metrics for regression</h5><ul>
<li>The common performance measure for regression is <em>mean squared error (MSE)</em> .</li>
<li>For a dateset $D=\{(\pmb x_i,y_i):i=1,2,\cdots,m\}$ , <script type="math/tex">\hat R_D(\hat f)=\cfrac{1}{m}\sum_{i=1}^m(\hat f(\pmb x_i)-y_i)^2</script></li>
<li>Some other performance measures<ul>
<li>Root Mean Square Error (RMSE)</li>
<li>Mean Absolute Error (MAE)</li>
<li>$R^2$</li>
</ul>
</li>
</ul>
<h3 id="Bias-variance-decomposition"><a href="#Bias-variance-decomposition" class="headerlink" title="Bias-variance decomposition"></a>Bias-variance decomposition</h3><ul>
<li>Given a training set $S=\{(\pmb x_i,y_i),i=1,2,\cdots,m\}$ such that each sample $(\pmb x_i,y_i)$ satisfies the following relationship <script type="math/tex">y=f(\pmb x)+\epsilon</script><ul>
<li>$\epsilon$ is the noise with mean zero and variance $\sigma^2$ .</li>
</ul>
</li>
<li>Let $\hat f(\pmb x;S)$ denote the estimated function that is trained with the set $S$ </li>
<li><p>For an unseen sample $(\pmb x_0,y_0)$ ,</p>
<ul>
<li>the predicted value using the function trained with $S$ is $\hat f(\pmb x_0;S)$ </li>
<li>the expected predicted value is $\mathbb E_S[\hat f(\pmb x_0;S)]$ </li>
<li>the true value is $f(\pmb x_0)$ </li>
<li>the bias (偏差) of the predicted value is <script type="math/tex">\text{Bias}[\hat f(\pmb x_0;S)]=\mathbb E[\hat f(\pmb x_0;S)]-f(\pmb x_0)</script></li>
<li>the variance (方差) of the predicted value is <script type="math/tex">\text{Var}[\hat f(\pmb x_0;S)]=\mathbb E\left[(\hat f(\pmb x_0;S)-\mathbb E[\hat f(\pmb x_0;S)])^2\right]</script></li>
<li>the expected squared error, where the expectation is over the random noise and the training set, is given by <script type="math/tex">E\left[(y_0-\hat f(\pmb x_0;S))^2\right]=(\text{Bias}[\hat f(\pmb x_0;S)])^2+\text{Var}[\hat f(\pmb x_0;S)]+\sigma^2</script></li>
<li>proof: <script type="math/tex">\begin{align}
&\mathbb E\left[(y_0-\hat f(\pmb x_0;S))^2\right]\\
=&\mathbb E\left[(y_0-\textcolor{red}{\mathbb E[\hat f(\pmb x_0;S)]+\mathbb E[\hat f(\pmb x_0;S)]}-\hat f(\pmb x_0;S))^2\right]\\
=&\mathbb E\left[(\mathbb E[\hat f(\pmb x_0;S)]-\hat f(\pmb x_0;S))^2+(y_0-\mathbb E[[\hat f(\pmb x_0;S)])^2+2(y_0-\mathbb E[\hat f(\pmb x_0;S)])(\mathbb E[\hat f(\pmb x_0;S)]-\hat f(\pmb x_0;S))\right]\\
=&\mathbb E\left[(\mathbb E[\hat f(\pmb x_0;S)]-\hat f(\pmb x_0;S))^2\right]+\mathbb E[(y_0-\mathbb E[\hat f(\pmb x_0;S)])^2]+\mathbb E[2(y_0-\mathbb E[\hat f(\pmb x_0;S)])(\mathbb E[\hat f(\pmb x_0;S)]-\hat f(\pmb x_0;S))]\\
=&\mathbb E\left[(\mathbb E[\hat f(\pmb x_0;S)]-\hat f(\pmb x_0;S))^2\right]+\mathbb E [(\textcolor{red}{f(\pmb x_0)+\epsilon}-\mathbb E[\hat f(\pmb x_0;S)])^2]\\
=&\mathbb E\left[(\mathbb E[\hat f(\pmb x_0;S)]-\hat f(\pmb x_0;S))^2\right]+\mathbb E[\hat f(\pmb x_0)-\mathbb E[\hat f(\pmb x_0;S)])^2]+\mathbb E[\epsilon^2]+\mathbb E[2\epsilon(f(\pmb x_0)-\mathbb E[\hat f(\pmb x_0;S)])]\\
=&\text{Var}[\hat f(\pmb x_0;S)]+(\text{Bias}[\hat f(\pmb x_0;S)])^2+\sigma^2
\end{align}</script></li>
</ul>
</li>
<li><p>The <em>variance</em> represents how much the trained model move about its mean.</p>
</li>
<li><p>The <em>bias</em> represents the difference between the expected prediction of our model and the true value.<br><img src="/pic/e4f39df5e0cf02295ed0adf94236c82.png" srcset="/img/loading.gif" lazyload alt=""><br><img src="/pic/4010e1c4642202ac977ba16ffc9a0ee.png" srcset="/img/loading.gif" lazyload alt=""></p>
</li>
<li><p>The ideal case is that we reduce both the bias and variance to reduce the total error.</p>
</li>
<li>However, there is a trade-off between the bias and variance.<ul>
<li>High bias: more features, more complex models, better optimization, boosting, …</li>
<li>High variance: more data, regularization, less features, less complex models, bagging, …<br><img src="/pic/b0f3730daa3d994524a12413137e863.png" srcset="/img/loading.gif" lazyload alt=""></li>
</ul>
</li>
</ul>
<h3 id="Model-selection"><a href="#Model-selection" class="headerlink" title="Model selection"></a>Model selection</h3><p>Fit the data (blue dots) using polynomials with different degrees of freedom.</p>
<ul>
<li>How to select the appropriate model with good fit?<br><img src="/pic/1a58a26150be5c680563a0eb25d7b8a.png" srcset="/img/loading.gif" lazyload alt=""></li>
</ul>
<h4 id="Principle-of-Occam’s-razor-奥卡姆剃刀"><a href="#Principle-of-Occam’s-razor-奥卡姆剃刀" class="headerlink" title="Principle of Occam’s razor (奥卡姆剃刀)"></a>Principle of Occam’s razor (奥卡姆剃刀)</h4><ul>
<li>Select the hypothesis with the fewest assumptions among all competing hypotheses that explain known observations equally well.<br><img src="/pic/30dc5adbbd599316a0cb17da5726c8c.png" srcset="/img/loading.gif" lazyload alt=""></li>
</ul>
<h4 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h4><ul>
<li>Regularization(正则化) refers to the process of adding additional terms to our loss function, often to introduce a <u>preference for simpler models</u></li>
<li>It aims to reduce the generalization error but not its training error.</li>
<li>Recall the training error $\hat R_S(f)=\cfrac{1}{m}\displaystyle\sum_{i=1}^mL(f(\pmb x_i),y_i)$ , we search for the hypothesis that leads to the smallest training error <script type="math/tex">\min_{f\in F}\hat R_S(f)</script></li>
<li><p>Minimization problem with regularized loss function <script type="math/tex">\min_{f\in F}\hat R_S(f)+\lambda E(f)</script><br><img src="/pic/f4eec853b3f60729c5dd34dc7b4acc9.png" srcset="/img/loading.gif" lazyload alt=""></p>
</li>
<li><p>$L_2$ regularization <script type="math/tex">E(f=\pmb w^T\pmb x)=||\pmb w||_2^2=\sum_{i=1}^nw_i^2</script><br><img src="/pic/0ad30f160f2e7ecab62f7354a1c4616.png" srcset="/img/loading.gif" lazyload alt=""></p>
</li>
<li><p>$L_1$ regularization <script type="math/tex">E(f=\pmb w^T\pmb x)=||\pmb w||_1=\sum_{i=1}^n|w_i|</script><br><img src="/pic/a28e0bebc2515f58f224263e5cbedf5.png" srcset="/img/loading.gif" lazyload alt=""></p>
</li>
</ul>
<h4 id="Hyperparameter-超参数"><a href="#Hyperparameter-超参数" class="headerlink" title="Hyperparameter(超参数)"></a>Hyperparameter(超参数)</h4><ul>
<li>The parameter is determined before the learning process<ul>
<li>Example: the degree of the polynomial, the regularization coefficient.</li>
</ul>
</li>
<li>It can not be adopted by the learning algorithm from the training data</li>
<li>How to find the optimal hyperparameter?<ul>
<li>Set it to different values</li>
<li>Evaluate the corresponding models</li>
<li>Choose the one that results in the best performance</li>
</ul>
</li>
</ul>
<h4 id="Validation-strategy"><a href="#Validation-strategy" class="headerlink" title="Validation strategy"></a>Validation strategy</h4><h5 id="Hold-out-validation"><a href="#Hold-out-validation" class="headerlink" title="Hold-out validation"></a>Hold-out validation</h5><ul>
<li>Split the training set into two parts: a training set and a validation set<br><img src="/pic/dd55e1c530692fa6810d9b314c15f84.png" srcset="/img/loading.gif" lazyload alt=""></li>
</ul>
<h5 id="Cross-validation"><a href="#Cross-validation" class="headerlink" title="Cross validation"></a>Cross validation</h5><ul>
<li>K-fold cross validation: divide the training set into k equal size subsets<br><img src="/pic/6c170feb2750e49af1c23e63965b608.png" srcset="/img/loading.gif" lazyload alt=""></li>
</ul>
<h5 id="Leave-one-out-cross-validation"><a href="#Leave-one-out-cross-validation" class="headerlink" title="Leave-one-out cross validation"></a>Leave-one-out cross validation</h5><ul>
<li><p>K-fold cross validation where $k=m$<br><img src="/pic/132f7b5bbcbb9caecf14d6a7f6bf2f0.png" srcset="/img/loading.gif" lazyload alt=""></p>
</li>
<li><p>Use one observation as the validation set</p>
</li>
<li>Each sample is used once for validation</li>
<li>It could be vary computationally intensive!</li>
</ul>
<h4 id="Which-validation-strategy-to-use"><a href="#Which-validation-strategy-to-use" class="headerlink" title="Which validation strategy to use?"></a>Which validation strategy to use?</h4><ul>
<li>Large data set<ul>
<li>Hold-out validation is simpler testing and computationally cheaper.</li>
<li>Hold-out strategy is suitable when the amount of data is huge.</li>
</ul>
</li>
<li>Small data set<ul>
<li>Cross-validation is useful when the dataset is small.</li>
<li>10-fold cross validation is common, but smaller values of k are often used when learning takes a lot of time</li>
</ul>
</li>
</ul>
<h2 id="Lecture4-LinearModels"><a href="#Lecture4-LinearModels" class="headerlink" title="Lecture4_LinearModels"></a>Lecture4_LinearModels</h2><h3 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h3><h4 id="Motivating-example"><a href="#Motivating-example" class="headerlink" title="Motivating example"></a>Motivating example</h4><ul>
<li>The Advertising data set consists of the <em>sales</em> of that product in 200 different markets, along with advertising budgets for the product in each of those markets for three different media: <em>TV, radio and newspaper</em>.<br><img src="8fce1beb900d9682237c079542b44f5.png" srcset="/img/loading.gif" lazyload alt=""></li>
</ul>
<h4 id="Simple-linear-regression"><a href="#Simple-linear-regression" class="headerlink" title="Simple linear regression"></a>Simple linear regression</h4><ul>
<li>Assuming approximately a linear relationship between $X$ and $Y$ <script type="math/tex">y\approx b+w\cdot x</script></li>
<li>Predicting $\hat y$ based on $x$ <script type="math/tex">\hat y=\hat b+\hat w\cdot x</script><br><img src="/pic/5192779dc145eba035b997cf1a76fcc.png" srcset="/img/loading.gif" lazyload alt=""></li>
</ul>
<h5 id="Estimating-the-parameters"><a href="#Estimating-the-parameters" class="headerlink" title="Estimating the parameters"></a>Estimating the parameters</h5><ul>
<li><p>Mean square error (MSE) <script type="math/tex">\begin{align}
MSE&=\cfrac{1}{m}((y_1-b-w\cdot x_1)^2+(y_2-b-w\cdot x_2)^2+\cdots+(y_m-b-w\cdot x_m)^2)\\
&=\cfrac{1}{m}\sum_{i=1}^m(y_i-b-w\cdot x_i)^2
\end{align}</script><br><img src="/pic/876fcd4c99289d7d14c2494c352de58.png" srcset="/img/loading.gif" lazyload alt=""></p>
</li>
<li><p>FInd the linear function with the smallest MSE <script type="math/tex">(\hat w,\hat b)=\text{arg}\min_{w,b}=\cfrac{1}{m}\sum_{i=1}^m(y_i-b-w\cdot x_i)^2</script></p>
</li>
<li>FOCs: <script type="math/tex">\begin{align}
\cfrac{\partial L(w,b)}{\partial w}&=\cfrac{1}{m}\sum_{i=1}^m2(y_i-b-w\cdot x_i)(-x_i)=0\\
\cfrac{\partial L(w,b)}{\partial b}&=\cfrac{1}{m}\sum_{i=1}^m2(y_i-b-w\cdot x_i)(-1)=0
\end{align}</script><script type="math/tex; mode=display">\begin{align}
\hat w&=\cfrac{\displaystyle\sum_{i=1}^m(x_i-\bar x)(y_i-\bar y)}{\displaystyle\sum_{i=1}^m(x_i-\bar x)^2},\ \ \ \ \hat b=\bar y-\hat w\bar x,\\
\bar x&=\cfrac{1}{m}\sum_{i=1}^mx_i, \ \ \ \ \bar y=\cfrac{1}{m}\sum_{i=1}^my_i
\end{align}</script></li>
</ul>
<p><img src="/pic/4cda0b999d6f3752153a5f48f5b45fa.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h4 id="Multivariate-linear-regression"><a href="#Multivariate-linear-regression" class="headerlink" title="Multivariate linear regression"></a>Multivariate linear regression</h4><ul>
<li>We ignore the other two factors when estimating the coefficients</li>
<li>How to make predictions given the levels of the three advertising media?<script type="math/tex">sales=b+w_1\cdot TV+w_2\cdot radio+w_3\cdot newspaper+\epsilon</script><br>In general, with $n$-dimension features, <script type="math/tex">\begin{align}
Y&\approx b+w_1\cdot x_1+w_2\cdot x_2+\cdots+w_n\cdot x_n\\
\hat y &=\hat b+\hat w_1\cdot x_1+\hat w_2\cdot x_2+\cdots+\hat w_n\cdot x_n
\end{align}</script><br>Choose $b,w_1,\cdots,w_n$ to minimize the following <script type="math/tex">MSE=\cfrac{1}{m}\sum_{i=1}^m(y_i-\hat y_i)^2=\cfrac{1}{m}\sum_{i=1}^m(y_i-b-\hat w_1\cdot x_{i,1}-\hat w_2\cdot x_{i,2}-\cdots-\hat w_n\cdot x_{i,n})^2</script><script type="math/tex; mode=display">\begin{align}
\pmb X&=\begin{bmatrix}
1 &x_{1,1} &\cdots &x_{i,n}\\
\vdots &\vdots &\ddots &\vdots\\
1 &x_{m,1} &\cdots &x_{m,n}
\end{bmatrix}\ \ \ \ m\times (n+1) \text{ matrix with each row a feature vector}\\
\pmb y&=[y_1,y_2,\cdots,y_m]^T\ \ \ \ m\times 1\text{ vector of outputs in the training set}\\
\pmb\beta &=[b,w_1,w_2,\cdots,w_n]^T\ \ \ \ (n+1)\times 1\text{ vector of parameters}
\end{align}</script></li>
</ul>
<p>Choose $\beta$ to minimize the following objective <script type="math/tex">MSE=\cfrac{1}{m}(\pmb y-\pmb X\pmb \beta)^T(\pmb y-\pmb X\pmb\beta)</script></p>
<script type="math/tex; mode=display">\min_{\pmb\beta} L(\pmb\beta)=\cfrac{1}{2}(\pmb y-\pmb X\pmb\beta)^T(\pmb y-\pmb X\pmb\beta)</script><script type="math/tex; mode=display">\cfrac{\partial L(\pmb\beta)}{\partial \pmb\beta}=-\pmb X^T(\pmb y-\pmb X\pmb\beta)</script><p>To minimize $L(\pmb\beta)$ , we set its derivatives to zero and obtain the normal equations <script type="math/tex">\cfrac{\partial L(\pmb\beta)}{\partial \pmb\beta}=-\pmb X^T(\pmb y-\pmb X\pmb\beta)=0\Rightarrow \pmb X^T\pmb X\hat{\pmb\beta}=\pmb X^T\pmb y</script><br>Suppose $\pmb X^T\pmb X$ is invertible, <script type="math/tex">\begin{align}
\hat{\pmb\beta}&=(\pmb X^T\pmb X)^{-1}\pmb X^T\pmb y\\
\hat y_i&=\pmb x_i^T\hat{\pmb\beta}=\pmb x_i^T(\pmb X^T\pmb X)^{-1}\pmb X^T\pmb y\\
\hat {\pmb y}&=\pmb X\hat{\pmb\beta}=\pmb X(\pmb X^T\pmb X)^{-1}\pmb X^T\pmb y
\end{align}</script></p>
<h5 id="Ridge-regression"><a href="#Ridge-regression" class="headerlink" title="Ridge regression"></a>Ridge regression</h5><ul>
<li>What if $\pmb X^T\pmb X$ is not invertible? <script type="math/tex">\min_{\pmb\beta}L(\pmb\beta)=(\pmb y-\pmb X\pmb\beta)^T(\pmb y-\pmb X\pmb\beta)+\lambda||\pmb\beta||_2^2</script> <script type="math/tex">\cfrac{\partial L(\pmb\beta)}{\partial \pmb\beta}=-2\pmb X^T(\pmb y-\pmb X\pmb\beta)+2\lambda\pmb\beta</script></li>
<li>To minimize $L(\pmb\beta)$ , we set its derivatives to zero: <script type="math/tex">(\lambda\pmb I+\pmb X^T\pmb X)\pmb\beta=\pmb X^T\pmb y</script></li>
<li>The estimator from Ridge regression is computed as: <script type="math/tex">\hat{\pmb\beta}_\text{ridge}=(\lambda\pmb I+\pmb X^T\pmb X)^{-1}\pmb X^T\pmb y\Leftarrow (\lambda\pmb I+\pmb X^T\pmb X)\text{ is invertible for }\lambda\textgreater 0</script></li>
</ul>
<h4 id="Regularized-linear-regression"><a href="#Regularized-linear-regression" class="headerlink" title="Regularized linear regression"></a>Regularized linear regression</h4><script type="math/tex; mode=display">(\pmb y-\pmb X\pmb\beta)^T(\pmb y-\pmb X\pmb\beta)+\lambda E(\pmb\beta^T\pmb x)</script><p>$\lambda$ : Regularization coefficient;<br>$E(\pmb\beta^T\pmb x)$ : Regularization term</p>
<ul>
<li>L2 regularization (Ridge regression)<ul>
<li>$E(f=\pmb\beta^T\pmb x)=||\pmb\beta||_2^2$</li>
<li>$\lambda\rightarrow 0, \hat{\pmb\beta}_\text{ridge}\rightarrow\hat{\pmb\beta}_{OLS}$</li>
<li>$\lambda\rightarrow\infty,\hat{\pmb\beta}_\text{ridge}\rightarrow 0$</li>
</ul>
</li>
<li>L1 regularization (Lasso regression)<ul>
<li>$E(f=\pmb\beta^T\pmb x)=||\pmb\beta||_1$</li>
<li>Some of coefficient estimates tend to zeros</li>
<li>Variable selection (sparse models)</li>
</ul>
</li>
</ul>
<h5 id="Regularization-1"><a href="#Regularization-1" class="headerlink" title="Regularization"></a>Regularization</h5><p>Ridge vs. Lasso: which one is better? </p>
<ul>
<li>Case 1: A relatively small number of features have substantial coefficients and the remaining features have parameters that are very small or equal to zero.<ul>
<li>Lasso regression</li>
</ul>
</li>
<li>Case 2: The response is a function of many features, all with parameters of roughly equal size.<ul>
<li>Ridge regression</li>
</ul>
</li>
<li>Neither ridge nor lasso regression would universally dominate the other</li>
<li>Which approach to use? How to determine $\lambda$ ?<ul>
<li>Cross validation! </li>
</ul>
</li>
</ul>
<h4 id="Linear-regression-Probabilistic-View"><a href="#Linear-regression-Probabilistic-View" class="headerlink" title="Linear regression: Probabilistic View"></a>Linear regression: Probabilistic View</h4><h5 id="Recap-Probability-amp-Statistics"><a href="#Recap-Probability-amp-Statistics" class="headerlink" title="Recap: Probability &amp; Statistics"></a>Recap: Probability &amp; Statistics</h5><h6 id="The-multivariate-Gaussian-distribution"><a href="#The-multivariate-Gaussian-distribution" class="headerlink" title="The multivariate Gaussian distribution"></a>The multivariate Gaussian distribution</h6><p>A random vector $X$ is said to have a multivariate normal (Gaussian) distribution with mean $\mu\in\mathbb R^n$ and covariance matrix $\Sigma \in S_{++}^n$ </p>
<script type="math/tex; mode=display">f_{X_1,X_2,\cdots,X_n}(x_1,x_2,\cdots,x_n)=\cfrac{1}{(2\pi)^\frac{n}{2}|\Sigma|^\frac{1}{2}}e^{-\frac{1}{2}(\pmb x-\mu)^T\Sigma^{-1}(\pmb x-\mu)}$$ We write this as $X\sim\mathcal N(\mu,\Sigma)$. 

![](/pic/bfd5b6d0bc87a6d76c69c391e921870.png)

When $n=1$ , it is a normal (Gaussian) distribution $\mathcal N(\mu_1,\Sigma_{11})$ .
$$f_{X_1}(x_1)=\cfrac{1}{(2\pi)^\frac{1}{2}|\Sigma_{11}|^\frac{1}{2}}e^{-\frac{1}{2}(x_1-\mu_1)^T\Sigma_{11}^{-1}(x_1-\mu_1)}</script><h5 id="Linear-regression-Probabilistic-View-1"><a href="#Linear-regression-Probabilistic-View-1" class="headerlink" title="Linear regression: Probabilistic View"></a>Linear regression: Probabilistic View</h5><p>Assume the response $Y$ is given by a deterministic function and an additive Gaussian noise. <script type="math/tex">y=\pmb\beta^T\pmb x+\epsilon,\text{ where }\epsilon\sim N(0,\sigma^2)</script></p>
<ul>
<li>The linear regression estimator is the maximum likelihood estimator of the data.</li>
<li>The likelihood function <script type="math/tex">P(\pmb y|\pmb X;\pmb\beta)=P(y_1|\pmb x_1;\pmb\beta)P(y_2|\pmb x_2;\pmb\beta)\cdots P(y_m|\pmb x_m;\pmb\beta)=\prod_{i=1}^mP(y_i|\pmb x_i;\pmb\beta)</script></li>
<li>The log-likelihood function <script type="math/tex">\log P(\pmb y|\pmb X;\pmb\beta)=\log\prod_{i=1}^m P(y_i|\pmb x_i;\pmb\beta)=\sum_{i=1}^m\log P(y_i|\pmb x_i;\pmb\beta)</script></li>
<li>Given dataset $(\pmb X,\pmb y)$ , find $\pmb\beta$ that can maximize the log-likelihood of $\pmb y$ . <script type="math/tex">\hat{\pmb\beta}=\text{arg}\max_{\pmb\beta}\log P(\pmb y|\pmb X;\pmb\beta)=\text{arg}\max_{\pmb\beta}\sum_{i=1}^m\log P(y_i|\pmb x_i;\pmb\beta)</script></li>
</ul>
<script type="math/tex; mode=display">\begin{align}
\hat{\pmb\beta}&=\text{arg}\max_{\pmb\beta}\log P(\pmb y|\pmb X;\pmb\beta)\\
&=\text{arg}\max_{\pmb\beta}\sum_{i=1}^m\log P(y_i|\pmb x_i;\pmb\beta)\\
&=\text{arg}\max_{\pmb\beta}\sum_{i=1}^m\log\cfrac{1}{\sqrt{2\pi\sigma^2}}e^{-\cfrac{(y_i-\pmb\beta^T\pmb x_i)^2}{2\sigma^2}}
\Leftarrow P(y_i|\pmb x_i;\pmb\beta)=\cfrac{1}{\sqrt{2\pi\sigma^2}}e^{-\cfrac{(y_i-\pmb\beta^T\pmb x_i)^2}{2\sigma^2}}\\
&=\text{arg}\max_{\pmb\beta}-\sum_{i=1}^m\cfrac{(y_i-\pmb\beta^T\pmb x_i)^2}{2\sigma^2}\\
&=\text{arg}\min_{\pmb\beta}\sum_{i=1}^m\cfrac{(y_i-\pmb\beta^T\pmb x_i)^2}{2\sigma^2}\\
&=\text{arg}\min_{\pmb\beta}\sum_{i=1}^m(y_i-\pmb\beta^T\pmb x_i)^2
\Leftrightarrow MSE=\frac{1}{m}(\pmb y-\pmb X\pmb\beta)^T(\pmb  y-\pmb X\pmb\beta)
\end{align}</script><h5 id="Ridge-regression-Probabilistic-View"><a href="#Ridge-regression-Probabilistic-View" class="headerlink" title="Ridge regression: Probabilistic View"></a>Ridge regression: Probabilistic View</h5><ul>
<li>Assume the response $Y$ is given by a deterministic function and an additive Gaussian noise. <script type="math/tex">y=\pmb\beta^T\pmb x+\epsilon,\text{ where }\epsilon\sim N(0,\sigma^2)</script></li>
<li>Suppose $\pmb\beta$ has the prior $p(\pmb\beta)=\mathcal N(0,\tau^2\pmb I)$</li>
<li>Ridge regression estimator is a MAP estimator with Gaussian prior <script type="math/tex">\begin{align}
\hat{\pmb\beta}_{MAP}&=\text{arg}\max\sum_{i=1}^m\log p(y_i|\pmb x_i;\pmb\beta)+\log p(\pmb\beta)\\
P(y_i|\pmb x_i;\pmb\beta)=\cfrac{1}{\sqrt{2\pi\sigma^2}}e^{-\cfrac{(y_i-\pmb\beta^T\pmb x_i)^2}{2\sigma^2}}
\Rightarrow &=\text{arg}\max\sum_{i=1}^m-\cfrac{(y_i-\pmb\beta^T\pmb x_i)^2}{2\sigma^2}-\cfrac{1}{2\tau^2}||\pmb\beta||_2^2
\Leftarrow p(\pmb\beta)=\cfrac{e^{-\cfrac{1}{2\tau^2}\pmb\beta^T\pmb\beta}}{\sqrt{(2\pi\tau^2)^n}}\\
&=\text{arg}\max_{\pmb\beta}\sum_{i=1}^m-(y_i-\pmb\beta^T\pmb x_i)^2-\lambda||\pmb\beta||_2^2
\Leftarrow \lambda=\cfrac{\sigma^2}{\tau^2}\\
\text{Ridge regression}\Leftrightarrow &=\text{arg}\min_{\pmb\beta}\sum_{i=1}^m(y_i-\pmb\beta^T\pmb x_i)^2+\lambda||\pmb\beta||_2^2
\end{align}</script><h3 id="Classification-1"><a href="#Classification-1" class="headerlink" title="Classification"></a>Classification</h3></li>
<li>In many situation, the response variable is qualitative. </li>
<li>Classification is a process of predicting qualitative responses.</li>
<li>Examples<ul>
<li>Medical diagnosis: predict whether a patient is sick or healthy</li>
<li>Spam detection: predict whether an email is spam or not</li>
<li>Credit card fraud: predict whether a given credit card transaction is fraud or not</li>
<li>Marketing: predict whether a given user will buy a product or not</li>
</ul>
</li>
<li>Classifiers<ul>
<li>Logistic regression</li>
<li>Support vector machine (SVM)</li>
<li>Naïve Bayesian</li>
<li>…</li>
</ul>
</li>
</ul>
<h4 id="Logistic-regression"><a href="#Logistic-regression" class="headerlink" title="Logistic regression"></a>Logistic regression</h4><h5 id="Why-not-linear-regression"><a href="#Why-not-linear-regression" class="headerlink" title="Why not linear regression?"></a>Why not linear regression?</h5><p>Can we use linear regression to predict the probability of default? <script type="math/tex">p(\pmb x)=\pmb w^T\pmb x+b</script></p>
<ul>
<li>The probability of default could be negative when balances close to 0, and could be bigger than 1 when the balances are large. </li>
<li>We must model $p(\pmb x)$ as a function that gives output between 0 and 1.<br><img src="/pic/8238a887080cb52105e2da7c8321fab.png" srcset="/img/loading.gif" lazyload alt=""></li>
</ul>
<h5 id="Logistic-function"><a href="#Logistic-function" class="headerlink" title="Logistic function"></a>Logistic function</h5><script type="math/tex; mode=display">\sigma(z)=\cfrac{1}{1+e^{-z}}</script><ul>
<li>bounded in (0,1)</li>
<li>$\sigma(z)\rightarrow 1$ when $z \rightarrow \infty$</li>
<li>$\sigma(z)\rightarrow 0$ when $z\rightarrow -\infty$</li>
<li>$\sigma^\prime(z)=\sigma(z)(1-\sigma(z))$</li>
</ul>
<h6 id="Binary-classification-using-logistic-function"><a href="#Binary-classification-using-logistic-function" class="headerlink" title="Binary classification using logistic function"></a>Binary classification using logistic function</h6><script type="math/tex; mode=display">\begin{align}
p(y=1|\pmb x)=\sigma(\pmb w^T\pmb x+b)=\cfrac{1}{1+e^{-(\pmb w^T\pmb x+b)}}\\
p(y=0|\pmb x)=1-\sigma(\pmb w^T\pmb x+b)=\cfrac{e^{-(\pmb w^T\pmb x+b)}}{1+e^{-(\pmb w^T\pmb x+b)}}
\end{align}</script><h6 id="Interpretation-of-logistic-regression"><a href="#Interpretation-of-logistic-regression" class="headerlink" title="Interpretation of logistic regression"></a>Interpretation of logistic regression</h6><ul>
<li>Let $p(\pmb x)=\cfrac{1}{1+e^{-(\pmb w^T\pmb x+b)}}$, the odds(几率) is given by, <script type="math/tex">odds=\cfrac{p(\pmb x)}{1-p(\pmb x)}=e^{\pmb w^T\pmb x+b}</script></li>
<li>If we take the logarithm on both sides, <script type="math/tex">\log\cfrac{p(\pmb x)}{1-p(\pmb x)}=\pmb w^T\pmb x+b</script></li>
<li>The logit of an event’s odds is predicted by a linear model.</li>
<li>One-unit increase in $x_i$ changes the log-odds by $w_i$ holding all other features fixed.</li>
</ul>
<h4 id="Training-the-logistic-function"><a href="#Training-the-logistic-function" class="headerlink" title="Training the logistic function"></a>Training the logistic function</h4><ul>
<li>We use the maximum likelihood estimation (MLE) to estimate $b$ and $\pmb w$</li>
<li><p>Let $\pmb \beta=[b;\pmb w]$ , the likelihood function is given by <script type="math/tex">\begin{align}
\mathcal L(\pmb \beta) &= \prod_{i:y_i=1}p(y_i=1|\pmb x_1;\pmb\beta)\prod_{i^\prime:y_{i^\prime}=0}p(y_{i^\prime}=0|\pmb x_{i^\prime};\pmb \beta)\\
&=\prod_{i=1}^mp(y_i=1|\pmb x_i;\pmb\beta)^{y_i}p(y_1=0|\pmb x_i;\pmb\beta)^{1-y_i}
\end{align}</script></p>
<script type="math/tex; mode=display">\begin{align}
p(y=1|\pmb x;\pmb\beta)=\sigma(\pmb\beta^T\pmb x)=\cfrac{1}{1+e^{-\pmb \beta^T\pmb x}}\\
p(y=0|\pmb x;\pmb\beta)=1-\sigma(\pmb\beta^T\pmb x)=\cfrac{e^{-\pmb\beta^T\pmb x}}{1+e^{-\pmb\beta^T\pmb x}}
\end{align}</script></li>
<li><p>We can equivalently minimize the <em>negative</em> log-likelihood function <script type="math/tex">\begin{align}
\mathcal{l(\pmb\beta)}&=-\log\mathcal{L(\pmb\beta)}\\
&=\sum_{i=1}^m(-y_i\log p(y_i=1|\pmb x_i;\pmb\beta)-(1-y_i)\log p(y_i=0|\pmb x_i;\pmb\beta))\\
&=\sum_{i=1}^m(-y_i\pmb\beta^T\pmb x_i+\log(1+e^{\pmb\beta^T\pmb x_i}))
\end{align}</script></p>
</li>
<li><p>Maximum Likelihood Estimation (MLE) <script type="math/tex">\begin{align}
\hat{\pmb\beta}&=\text{arg}\max_{\pmb\beta}\mathcal L(\pmb\beta)\\
&=\text{arg}\min_{\pmb\beta}\mathcal l(\pmb\beta)\\
&=\text{arg}\min_{\pmb\beta}\sum_{i=1}^m(-y_i\pmb\beta^T\pmb x_i+\log(1+e^{\pmb\beta^T\pmb x_i}))
\end{align}</script></p>
</li>
<li>There is no closed-form solution for the above optimization problem</li>
<li>Fortunately, $\mathcal l(\pmb\beta)$ is a convex function, we can apply the <em>gradient descent method</em> to find the optimal solution.</li>
</ul>
<h5 id="Gradient-descent-method-梯度下降法"><a href="#Gradient-descent-method-梯度下降法" class="headerlink" title="Gradient descent method (梯度下降法)"></a>Gradient descent method (梯度下降法)</h5><ul>
<li>Recall: gradient is the direction of fastest increase</li>
<li>Updating rule <script type="math/tex; mode=display">\pmb \beta_{new}\leftarrow\pmb \beta_{old}-\eta\nabla\mathcal l(\pmb \beta)</script></li>
<li>Search procedure<ol>
<li>Choose an initial value for $\pmb\beta$</li>
<li>Update $\pmb\beta$ iteratively<ol>
<li>Take the derivative of $\mathcal l(\pmb\beta)$</li>
<li>Move the parameters in the direction of steepest descent</li>
</ol>
</li>
<li>Stop until <strong>convergence</strong><br><img src="/pic/6360a7faf1d39affd8e0985f07daa4a.png" srcset="/img/loading.gif" lazyload alt=""></li>
</ol>
</li>
</ul>
<h5 id="Batch-gradient-descent-批量梯度下降"><a href="#Batch-gradient-descent-批量梯度下降" class="headerlink" title="Batch gradient descent (批量梯度下降)"></a>Batch gradient descent (批量梯度下降)</h5><script type="math/tex; mode=display">\begin{align}
\mathcal l(\pmb\beta)&=\sum_{i=1}^m(-y_i\pmb\beta^T\pmb x_i+\log(1+e^{\pmb\beta^T\pmb x_i}))\\
\nabla\mathcal l(\pmb\beta)&=-\sum_{i=1}^m\pmb x_i(y_i-p(y_i=1|\pmb x;\pmb\beta))
\end{align}</script><p>Update $\pmb\beta$ using the whole batch</p>
<script type="math/tex; mode=display">\pmb\beta_{new}\leftarrow\pmb\beta_{old}+\eta\sum_{i=1}^m\pmb x_i(y_i-p(y=1|\pmb x;\pmb\beta_{old}))</script><p><img src="/pic/a07605c556f05131fcb0eed75e8fe92.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h5 id="Stochastic-gradient-descent-随机梯度下降"><a href="#Stochastic-gradient-descent-随机梯度下降" class="headerlink" title="Stochastic gradient descent (随机梯度下降)"></a>Stochastic gradient descent (随机梯度下降)</h5><script type="math/tex; mode=display">\begin{align}
\mathcal l(\pmb\beta)=\sum_{i=1}^m-y_i\pmb\beta^T\pmb x_i+\log(1+e^{\pmb\beta^T\pmb x_i})=\sum_{i=1}^m\mathcal l^{(i)}(\pmb\beta)\\
\text{where } \mathcal l^{(i)}(\pmb\beta)=-y_i\pmb\beta^T\pmb x_i+\log(1+e^{\pmb\beta^T\pmb x_i})\\
\nabla\mathcal l^{(i)}(\pmb\beta)=-\pmb x_i(y_i-p(y_i=1|\pmb x_i;\pmb\beta))
\end{align}</script><p>Update $\pmb\beta$ using single data sample</p>
<script type="math/tex; mode=display">\pmb\beta_{new}\leftarrow\pmb\beta_{old}+\eta\pmb x_i(y_i-p(y_i=1|\pmb x_i;\pmb\beta_{old}))</script><p><img src="/pic/c04750dc47e5320cec59791c2897602.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h5 id="Mini-batch-gradient-descent-小批量梯度下降"><a href="#Mini-batch-gradient-descent-小批量梯度下降" class="headerlink" title="Mini-batch gradient descent (小批量梯度下降)"></a>Mini-batch gradient descent (小批量梯度下降)</h5><ul>
<li>A combination of batch GD and stochastic GD<ul>
<li>Split the whole dataset into $K$ mini-batches $\{1,2,3\cdots,K\}$</li>
<li>For each mini-batch $k$, perform one-step BGD to minimize<script type="math/tex; mode=display">\begin{align}
\mathcal l^k(\pmb\beta)&=\sum_{i=1}^{n_k}-y_i\pmb\beta^T\pmb x_i+\log(1+e^{\pmb\beta^T\pmb x_i})\\
\nabla\mathcal l^k(\pmb\beta)&=-\sum_{i=1}^{n_k}\pmb x_i(y_i-p(y_i=1|\pmb x_i;\pmb\beta))
\end{align}</script>Update $\pmb\beta$ using a mini-batch of data samples<script type="math/tex; mode=display">\pmb\beta_{new}\leftarrow\pmb\beta_{old}+\eta\sum_{i=1}^{n_k}\pmb x_i(y_i-p(y=1|\pmb x_i;\pmb\beta_{old}))</script></li>
</ul>
</li>
</ul>
<h5 id="Choice-of-learning-rate-学习速率"><a href="#Choice-of-learning-rate-学习速率" class="headerlink" title="Choice of learning rate (学习速率)"></a>Choice of learning rate (学习速率)</h5><p><img src="/pic/4e3d1c319b8d2121651b340bb9e0379.png" srcset="/img/loading.gif" lazyload alt=""></p>
<ul>
<li>Gradient descent would take long time to converge and can be very slow</li>
</ul>
<p><img src="/pic/28249e9b76fddb1d028bad646f5b33e.png" srcset="/img/loading.gif" lazyload alt=""></p>
<ul>
<li>May overshoot the minimum</li>
<li>The algorithm may fail to converge, or even diverge</li>
</ul>
<p><img src="/pic/34a695cff223faf29380cb4cd036595.png" srcset="/img/loading.gif" lazyload alt=""></p>
<ul>
<li>For sufficiently small $\eta$, the loss function should decrease on every iteration.</li>
<li>Plot the loss function as a function of number of iterations to see if the learning rate is appropriate</li>
</ul>
<h4 id="Making-prediction"><a href="#Making-prediction" class="headerlink" title="Making prediction"></a>Making prediction</h4><h5 id="Label-decision-and-thresholds"><a href="#Label-decision-and-thresholds" class="headerlink" title="Label decision and thresholds"></a>Label decision and thresholds</h5><ul>
<li>Logistic regression provides the probability of one event belonging to a class or another</li>
<li>The final label of an instance is decided by setting a threshold $h$ (typically 0.5)<script type="math/tex; mode=display">\hat y=\begin{cases}
1&,\ \ \ \ p(y=1|\pmb x)\textgreater h\\
0&,\ \ \ \ otherwise
\end{cases}</script></li>
<li><p>How to choose the threshold?<br>| | Higher threshold | lower threshold |<br>|—-|—-|—-|<br>| False Negative (FN) | $\uparrow$ | $\downarrow$ |<br>| False Positive (FP) | $\downarrow$ | $\uparrow$ |</p>
</li>
<li><p>Don’t get confused by its name! It’s a classification rather than regression algorithm</p>
</li>
</ul>
<h5 id="Another-evaluation-measure-ROC-curve"><a href="#Another-evaluation-measure-ROC-curve" class="headerlink" title="Another evaluation measure: ROC curve"></a>Another evaluation measure: ROC curve</h5><p>Receiver Operating Characteristic (ROC) curve</p>
<ul>
<li>ROC curve plots True Positive rate vs. False Positive rate at different thresholds between 0 and 1</li>
<li>It shows the trade-off between true-positive rate and false-positive rate of classification algorithms</li>
<li>True Positive rate (recall, 真正例率)<script type="math/tex; mode=display">TPR=\cfrac{TP}{TP+FN}</script></li>
<li>False Positive rate (假正例率)<script type="math/tex; mode=display">FPR=\cfrac{FP}{FP+TN}</script><img src="/pic/6a2e08f093e043bef56e9524d47d15f.png" srcset="/img/loading.gif" lazyload alt=""></li>
</ul>
<h5 id="ROC-curve-and-AUC-area-under-the-curve"><a href="#ROC-curve-and-AUC-area-under-the-curve" class="headerlink" title="ROC curve and AUC (area under the curve)"></a>ROC curve and AUC (area under the curve)</h5><p><img src="/pic/2beb86993fa4ae74f0081ec91c2c703.png" srcset="/img/loading.gif" lazyload alt=""></p>
<ul>
<li>In this example, Classifier A is better than B, which is better than random guessing</li>
</ul>
<p><img src="/pic/ab20f3bcdac435adab7fbe44748781b.png" srcset="/img/loading.gif" lazyload alt=""></p>
<ul>
<li>Compare multiple models by a single number </li>
<li>Higher AUC will be the better </li>
<li>However, it does not tell us the performance of the model for a given threshold setting</li>
</ul>
<h4 id="Regularization-in-logistic-regression"><a href="#Regularization-in-logistic-regression" class="headerlink" title="Regularization in logistic regression"></a>Regularization in logistic regression</h4><ul>
<li>Without regularization, the logistic regression would keep driving the loss towards 0 in high dimensions.</li>
<li>L1 regularization<script type="math/tex; mode=display">\mathcal l(\pmb\beta)+E(\pmb\beta)=\mathcal l(\pmb\beta)+\cfrac{\lambda}{2}\sum_{i=1}^n|\beta_i|</script></li>
<li>L2 regularization<script type="math/tex; mode=display">\mathcal l(\pmb\beta)+E(\pmb\beta)=\mathcal l(\pmb\beta)+\cfrac{\lambda}{2}\sum_{i=1}^n\beta_i^2</script></li>
<li>Early stopping, that is, limiting the number of training steps or the learning rate.</li>
</ul>
<h4 id="Multiclass-classification-多分类"><a href="#Multiclass-classification-多分类" class="headerlink" title="Multiclass classification (多分类)"></a>Multiclass classification (多分类)</h4><ul>
<li>Email tagging: Work, Friends, Family, Hobby</li>
<li>Medical diagrams: Healthy, Cold, Flu</li>
<li>Weather: Sunny, Windy, Rainy<br><img src="/pic/0dbd9f34a7dd01a3cf8fdff2267228b.png" srcset="/img/loading.gif" lazyload alt=""></li>
</ul>
<h5 id="Multinomial-logistic-regression-多项逻辑回归"><a href="#Multinomial-logistic-regression-多项逻辑回归" class="headerlink" title="Multinomial logistic regression (多项逻辑回归)"></a>Multinomial logistic regression (多项逻辑回归)</h5><ul>
<li>The label can take values from the set $\{1,2,\cdots,K\}$</li>
<li>The multinomial logistic regression model is given as,<script type="math/tex">\begin{align}
P(Y=k|x)&=\cfrac{e^{\pmb\beta^T_k\pmb x}}{1+\displaystyle\sum_{i=1}^{K-1}e^{\pmb\beta^T_i\pmb x}},\ \ \ \ k=1,2,\cdots,K-1\\
P(Y=K|\pmb x)&=\cfrac{1}{1+\displaystyle\sum_{i=1}^{K-1}e^{\pmb\beta_i^T\pmb x}}\\
\end{align}</script></li>
<li>The parameters can be estimated by the MLE approach <script type="math/tex">\max_{\beta_k,k=1,2,\cdots,K-1}\sum_{i=1}^m\sum_{k=1}^Ky_i^k\log P(y_i^k=1|\pmb x_i)</script></li>
</ul>
<h5 id="One-vs-Rest-OvR"><a href="#One-vs-Rest-OvR" class="headerlink" title="One-vs-Rest (OvR)"></a>One-vs-Rest (OvR)</h5><p><img src="/pic/3b345e6e23b44d137f2eef677b086a0.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h5 id="One-vs-One-OvO"><a href="#One-vs-One-OvO" class="headerlink" title="One-vs-One (OvO)"></a>One-vs-One (OvO)</h5><p><img src="/pic/163ee69801c5fd90f0db8434f12c0a0.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h2 id="Lecture5-FeatureEngineering"><a href="#Lecture5-FeatureEngineering" class="headerlink" title="Lecture5_FeatureEngineering"></a>Lecture5_FeatureEngineering</h2><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><h3 id="Data-understanding"><a href="#Data-understanding" class="headerlink" title="Data understanding"></a>Data understanding</h3><h4 id="Structured-versus-unstructured-data"><a href="#Structured-versus-unstructured-data" class="headerlink" title="Structured versus unstructured data"></a>Structured versus unstructured data</h4><h4 id="Quantitative-versus-qualitative-data"><a href="#Quantitative-versus-qualitative-data" class="headerlink" title="Quantitative versus qualitative data"></a>Quantitative versus qualitative data</h4><h4 id="Exploratory-data-analysis-descriptive-statistics-and-data-visualizations"><a href="#Exploratory-data-analysis-descriptive-statistics-and-data-visualizations" class="headerlink" title="Exploratory data analysis: descriptive statistics and data visualizations"></a>Exploratory data analysis: descriptive statistics and data visualizations</h4><h3 id="Data-processing"><a href="#Data-processing" class="headerlink" title="Data processing"></a>Data processing</h3><h4 id="Missing-values"><a href="#Missing-values" class="headerlink" title="Missing values"></a>Missing values</h4><h4 id="Class-imbanlance"><a href="#Class-imbanlance" class="headerlink" title="Class imbanlance"></a>Class imbanlance</h4><h4 id="Feature-scaling-amp-discretization"><a href="#Feature-scaling-amp-discretization" class="headerlink" title="Feature scaling &amp; discretization"></a>Feature scaling &amp; discretization</h4><h4 id="Feature-encoding-amp-text-data-representation"><a href="#Feature-encoding-amp-text-data-representation" class="headerlink" title="Feature encoding &amp; text data representation"></a>Feature encoding &amp; text data representation</h4><h2 id="Lecture7-NeuralNetworks"><a href="#Lecture7-NeuralNetworks" class="headerlink" title="Lecture7_NeuralNetworks"></a>Lecture7_NeuralNetworks</h2><h3 id="Overview-of-neural-networks"><a href="#Overview-of-neural-networks" class="headerlink" title="Overview of neural networks"></a>Overview of neural networks</h3><h4 id="Structure-of-neurons-in-human-brain"><a href="#Structure-of-neurons-in-human-brain" class="headerlink" title="Structure of neurons in human brain"></a>Structure of neurons in human brain</h4><ul>
<li>The human brain can be described as a biological neural network—an interconnected web of neurons transmitting elaborate patterns of electrical signals.</li>
<li>Dendrites receive input signals and, based on those inputs, fire an output signal via an axon.</li>
</ul>
<p><img src="/pic/d6ac10786053cf27bd83808148d4005.png" srcset="/img/loading.gif" lazyload alt=""></p>
<ul>
<li>Dendrite (树突): It receives signals from other neurons</li>
<li>Cell body: It sums all the incoming signals to generate input</li>
<li>Axon (轴突): When the sum reaches a threshold value, neuron fires and the signal travels down the axon to the other neurons</li>
</ul>
<h4 id="Artificial-neurons"><a href="#Artificial-neurons" class="headerlink" title="Artificial neurons"></a>Artificial neurons</h4><ul>
<li>Artificial neurons (人工神经元) are the basic computing units of information processing in an artificial neural network (人工神经网络).</li>
<li>The dendrites carry the signals (inputs $\pmb x$) to the cell body where they all get summed (weighted sum of inputs)</li>
<li>Synaptic strength (突触强度) controls the strength of the influence and direction (weights $\pmb w$)</li>
<li>Cell body reaches certain threshold and sends a spike to the next axon (activation function $f$)</li>
<li>Axons pass signals (outputs $\pmb y$) to other neurons (nodes)</li>
</ul>
<h4 id="Artificial-Neural-Networks-ANN"><a href="#Artificial-Neural-Networks-ANN" class="headerlink" title="Artificial Neural Networks (ANN)"></a>Artificial Neural Networks (ANN)</h4><ul>
<li>Artificial neural networks (ANN) are computing systems inspired by the biological neural networks.</li>
<li>It is comprised of a network of artificial neurons (nodes).</li>
</ul>
<p><img src="/pic/99505909a8ce803cd2585640c29ea03.png" srcset="/img/loading.gif" lazyload alt=""></p>
<ul>
<li>The connections between units do not form a cycle.</li>
<li><p>The information moves in only one direction.</p>
</li>
<li><p>Artificial neural networks (ANN) is best used</p>
<ul>
<li>For modeling highly nonlinear systems</li>
<li>When the model interpretability is not a key concern</li>
<li>When data is available incrementally and you wish to constantly update the model</li>
</ul>
</li>
<li>Applications<ul>
<li>Image recognition</li>
<li>Speech recognition</li>
<li>Natural language processing</li>
<li>Game AI</li>
<li>…</li>
</ul>
</li>
</ul>
<h4 id="History-of-neural-networks"><a href="#History-of-neural-networks" class="headerlink" title="History of neural networks"></a>History of neural networks</h4><ul>
<li><strong>The First wave</strong><ul>
<li>1943 McCulloch and Pitts proposed the McCulloch-Pitts neuron model (M-P神经元)</li>
<li>1958 Rosenblatt introduced the simple single layer networks now called Perceptrons (感知机).</li>
<li>1969 Minsky and Papert’s book Perceptrons demonstrated the limitation of single layer perceptron, and almost the whole field went into hibernation.</li>
</ul>
</li>
<li><strong>The Second wave</strong><ul>
<li>1986 The Back-Propagation learning algorithm (反向传播学习算法) for Multi-Layer Perceptrons was rediscovered and the whole field took off again.</li>
</ul>
</li>
<li><strong>The Third wave</strong><ul>
<li>2006 Deep (neural networks) Learning (深度学习) gains popularity</li>
<li>2012 made significant break-through in many applications<ul>
<li>AlexNet: Geoffrey Hinton, IIya Sutskever, Alex Krizhevsky</li>
<li>Google Brain: Jeff Dean, Andrew Ng</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Perceptron-model"><a href="#Perceptron-model" class="headerlink" title="Perceptron model"></a>Perceptron model</h3><ul>
<li>Rosenblatt’s single layer perceptron, 1958<ul>
<li>The simplest feedforward neural network. It does not contain any hidden layers.</li>
<li>It computes the weighted output, and uses a threshold activation function to output a quantity.</li>
</ul>
</li>
</ul>
<p><img src="/pic/31005d52795dd6bf9d6ccb279d59ceb.png" srcset="/img/loading.gif" lazyload alt=""></p>
<ul>
<li><em>Activation function (激活函数)</em> <script type="math/tex">f(z)=\begin{cases}
1 &\text{if } z\geq 0\\
0 &\text{otherwise}
\end{cases}</script></li>
<li>Prediction <script type="math/tex">\hat y=f\left(\sum_iw_ix_i+b\right)</script></li>
</ul>
<h4 id="Training-the-Perceptron-model"><a href="#Training-the-Perceptron-model" class="headerlink" title="Training the Perceptron model"></a>Training the Perceptron model</h4><ul>
<li>Perceptron uses iterative algorithm to learn a correct set of weights</li>
<li>Updating rule <script type="math/tex">\begin{align}
w_i\leftarrow w_i+\Delta w_i\\
\Delta w_i=\eta(y-\hat y)x_i
\end{align}</script><ul>
<li>$\eta$ : Learning rate</li>
<li>$y$ : Target output</li>
<li>$\hat y$ : Perceptron output</li>
</ul>
</li>
<li>Rosenblatt proved the convergence of the learning algorithm, if<ul>
<li>the training data is linearly separable</li>
<li>$\eta$ is sufficiently small</li>
</ul>
</li>
</ul>
<h4 id="Representation-of-Boolean-functions-布尔函数"><a href="#Representation-of-Boolean-functions-布尔函数" class="headerlink" title="Representation of Boolean functions (布尔函数)"></a>Representation of Boolean functions (布尔函数)</h4><p><img src="/pic/f7eb0da81ed0871c9b951828e1eef00.png" srcset="/img/loading.gif" lazyload alt=""></p>
<ul>
<li>AND ($x_1 \wedge x_2$ , 与)<ul>
<li>$w_1=w_2=1,b=-1.5$</li>
</ul>
</li>
<li>OR ($x_1\vee x_2$ , 或)<ul>
<li>$w_1=w_2=1,b=-0.5$</li>
</ul>
</li>
<li>NOT ($\overline{x_1}$ , 非)<ul>
<li>$w_1=-0.6,w_2=0,b=0.5$</li>
</ul>
</li>
</ul>
<h5 id="Limitation-of-Perceptron-model"><a href="#Limitation-of-Perceptron-model" class="headerlink" title="Limitation of Perceptron model"></a>Limitation of Perceptron model</h5><p>XOR ($\overline{x_1}\wedge x_2+\overline{x_2}\vee x_1$ , 异或)<br>| Input | |  Output |<br>|—-|—-|—-|<br>| $x_1$ | $x_2$ | $y$ |<br>| 0 | 0 | 0 |<br>| 0 | 1 | 1 |<br>| 1 | 0 | 1 |<br>| 1 | 1 | 0 |</p>
<p><img src="/pic/44f6ee7c2003c9bfdc6952ad6a82bb8.png" srcset="/img/loading.gif" lazyload alt=""></p>
<ul>
<li>XOR is not linearly separable</li>
<li>Some elementary computations such as XOR cannot be represented by Rosenblatt’s single layer perceptron</li>
</ul>
<h5 id="Solution-Add-a-hidden-layer"><a href="#Solution-Add-a-hidden-layer" class="headerlink" title="Solution - Add a hidden layer"></a>Solution - Add a hidden layer</h5><p><img src="/pic/7932e2084b642ada22ad4a78f912adf.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h3 id="Multi-layer-feedforward-neural-networks"><a href="#Multi-layer-feedforward-neural-networks" class="headerlink" title="Multi-layer feedforward neural networks"></a>Multi-layer feedforward neural networks</h3><p>Input layer (输入层) </p>
<ul>
<li>No computation performed</li>
<li>Pass information to hidden layers<br>Hidden layer (隐藏层)</li>
<li>Intermediate layer between input and output layers</li>
<li>Activation function apply on those layers</li>
<li>Can be multiple hidden layers<br>Output layer (输出层)</li>
<li>Transferring information to outside world<br><img src="cf8051b1925bef0c1100e19ec7ecdc2.png" srcset="/img/loading.gif" lazyload alt=""></li>
</ul>
<p><img src="46bc95f08fe1f0d64f8f9a4733f00b0.png" srcset="/img/loading.gif" lazyload alt=""></p>
<script type="math/tex; mode=display">\begin{align}
\alpha_j=\sum_{i=1}^dv_{ij}x_i\\
\beta_l=\sum_{j=1}^qw_{ji}b_j\\
\end{align}</script><p>Forward prediction</p>
<script type="math/tex; mode=display">x=(x_1,x_2,\cdots,x_d)\overset{b_j=f(\alpha_j)=f(\sum_{i=1}^dv_{ij}x_i)}{\longrightarrow}b_j\overset{y_i=f(\beta_i)=f(\sum_{j=1}^qw_{ji}b_j)}{\longrightarrow}y_i</script><p>For the training sample $(\pmb x_k,\pmb y_k)$ , the square error loss is <script type="math/tex">E_k=\cfrac{1}{2}\sum_{t=1}^l(\hat y_t^k-y_t^k)^2</script></p>
<p>The accumulated square error loss of dataset $S=\{(\pmb x_k,\pmb y_k): 1,2,\cdots, m\}$ is <script type="math/tex">\begin{align}
E&=\cfrac{1}{m}\sum_{k=1}^mE_k\\
&=\cfrac{1}{2m}\sum_{k=1}^m\sum_{t=1}^l(\hat y_t^k-y_t^k)^2
\end{align}</script></p>
<h4 id="Back-Propagation-algorithm"><a href="#Back-Propagation-algorithm" class="headerlink" title="Back-Propagation algorithm"></a>Back-Propagation algorithm</h4><p><img src="/pic/60f7ff4efd734ff604959c09c02b128.png" srcset="/img/loading.gif" lazyload alt=""></p>
<script type="math/tex; mode=display">\begin{align}
\alpha_j=\sum_{i=1}^dv_{ij}x_i\\
\beta_l=\sum_{j=1}^qw_{jl}b_j
\end{align}</script><ul>
<li>Use <strong>gradient descent method</strong> to train the neural network</li>
<li>Updating rules <script type="math/tex">\begin{align}
\pmb w\leftarrow \pmb w+\Delta \pmb w\\
\pmb v\leftarrow \pmb v+\Delta \pmb v\\
\end{align}</script></li>
<li>Learning $\pmb w$ <script type="math/tex; mode=display">\begin{align}
\pmb w&\leftarrow \pmb w+\Delta \pmb w\\
\Delta w_{ji}&=-\eta\cfrac{\partial E_k}{\partial w_{jl}}\\
\cfrac{\partial E_k}{\partial w_{jl}}&=\cfrac{\partial E_k}{\partial\hat y_l^k}\cdot\cfrac{\partial\hat y_l^k}{\partial\beta_l}\cdot\cfrac{\partial\beta_l}{\partial w_{jl}}\ \ \ \ \text{(Chain rule)}\\
\\
\cfrac{\partial E_k}{\partial\hat y_l^k}&=(\hat y_l^k-y_l^k)\\
\\
\cfrac{\partial\hat y_l^k}{\partial\beta_l}&=f^\prime(\beta_l)\\
&=f(\beta_l)(1-f(\beta_l))\\
&=\hat y_l^k(1-\hat y_l^k)\\
\\
\cfrac{\partial\beta_l}{\partial w_{jl}}&=b_j\\
\\
\cfrac{\partial E_k}{\partial w_{jl}}&=b_j(\hat y_l^k-y_l^k)\hat y_l^k(1-\hat y_l^k)\\
\\
\Delta w_{jl}&=-\eta\cfrac{\partial E_k}{\partial w_{jl}}=-\eta b_j(\hat y_l^k-y_l^k)\hat y_l^k(1-\hat y_l^k)=\eta b_jg_l\\
g_l&=\hat y_l^k(1-\hat y_l^k)(y_l^k-\hat y_l^k)\ \ \ \ \text{("error" at node $l$)}
\end{align}</script></li>
</ul>
<p><code>Input: learning rate 𝜂 and data set 𝑆 = &#123;(𝒙_𝑘, 𝒚_𝑘, 𝑘=1,2, … ,𝑚&#125;</code><br><code>Initialize: 𝒘, 𝒗</code><br><code>Procedure: Repeat until convergence</code><br>    <code>For training sample k = 1,2,…,m do</code><br>        <code>Calculate predictions \hat 𝒚_𝑘 %Feedforward prediction</code><br>        <code>Calculate 𝑔_𝑡,𝑡=1,2, … 𝑙 %Back-propagate errors</code><br>        <code>Calculate 𝑒_𝑗,𝑗=1,2, … 𝑞 %Back-propagate errors</code><br>        <code>Calculate Δ𝒘, Δ𝒗       %Calculate weights gradients</code><br>        <code>Update 𝒘, 𝒗            %Update weights</code> </p>
<p><img src="/pic/9bc96b20dd2d9a83b34e6770feefa63.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h5 id="An-calculation-example"><a href="#An-calculation-example" class="headerlink" title="An calculation example"></a>An calculation example</h5><p><img src="/pic/cba0fc4f531383fa7eee44fe02e9de0.png" srcset="/img/loading.gif" lazyload alt=""><br>Assume that the neurons have a Sigmoid activation function:</p>
<ol>
<li>Perform a forward pass on the network</li>
<li>Perform a reverse pass (training) once with target = 0.5 and learning rate = 1</li>
<li>Perform a further forward pass and comment on the results</li>
</ol>
<p>(i)<br>Input to the top neuron: $(0.35\times0.1) + (0.9 \times 0.8) = 0.755$. $Out_1 = 0.68$<br>Input to the bottom neuron: $(0.9 \times 0.6) + (0.35 \times 0.4) = 0.68$. $Out_2 = 0.6637$<br>Input to the final neuron: $(0.3 \times 0.68) + (0.9 \times 0.6637) = 0.80$. $Output = 0.69$<br>(ii)<br>Output error $g = (y − \hat y)(1 − \hat y)\hat y = (0.5 − 0.69)(1 − 0.69)0.69 = −0.0406$</p>
<p>Errors for the hidden layer $e_1 = 𝑔 \times 𝑤_1 \times (1 − out_1) \times out_1 = −0.0406 \times 0.3 \times (1 − 0.68) \times 0.68 = −0.00265$<br>$e_2 = g \times w_2 \times (1 − out_2) \times out_2 = −0.0406 \times 0.9 \times (1 − 0.6637) \times 0.6637 = −0.008156$<br>Update the weights for the output layer<br>$w_1 \leftarrow w_1 +(\eta \times g \times out_1) = 0.3 + (−0.0406 \times 0.68) = 0.272392$<br>$w_2 \leftarrow w_2 + (\eta \times g \times out_2) = 0.9 + (−0.0406 × 0.6637) = 0.87305$ </p>
<p>Update the weights for the hidden layer 𝑤𝑤3 ← 𝑤𝑤3 + 𝜂𝜂 × 𝑒𝑒1 × 𝑥𝑥1 = 0.1 + −0.00265 × 0.35 = 0.0991 𝑤𝑤4 ← 𝑤𝑤4 + 𝜂𝜂 × 𝑒𝑒1 × 𝑥𝑥2 = 0.8 + −0.00265 × 0.9 = 0.7976 𝑤𝑤5 ← 𝑤𝑤5 + 𝜂𝜂 × 𝑒𝑒2 × 𝑥𝑥1 = 0.4 + −0.008156 × 0.35 = 0.3971 𝑤𝑤6 ← 𝑤𝑤6 + 𝜂𝜂 × 𝑒𝑒2 × 𝑥𝑥2 = 0.6 + −0.008156 × 0.9 = 0.5927 (iii) Input to the top neuron: 0.35 × 0.0991 + 0.9 × 0.7976 = 0.7525. Out1 = 0.6797 Input to the bottom neuron: 0.9 × 0.5927 + 0.35 × 0.3971 = 0.6724. Out2 = 0.662 Input to the final neuron: 0.272392 × 0.6797 + 0.87305 × 0.662 = 0.7631. Output = 0.682</p>
<h3 id="Activation-functions"><a href="#Activation-functions" class="headerlink" title="Activation functions"></a>Activation functions</h3><h3 id="Issues-of-training-neural-networks"><a href="#Issues-of-training-neural-networks" class="headerlink" title="Issues of training neural networks"></a>Issues of training neural networks</h3>
                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/2022S/" class="category-chain-item">2022S</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/" class="print-no-link">#课程笔记</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>机器学习-课程笔记</div>
      <div>http://hiryan23.github.io/2023/02/17/Machine Learning/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Ruiyang He</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2023年2月17日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2023/02/19/%E5%AF%B9chatgpt%E7%9A%84%E6%AC%A2%E5%91%BC%E6%98%AF%E4%BA%BA%E5%AF%B9%E5%BC%82%E5%8C%96%E7%9A%84%E5%8F%8D%E6%8A%97%E2%80%94%E2%80%94%E8%AE%BAai%E4%BB%A3%E5%86%99%E8%AE%BA%E6%96%87%E7%9A%84%E8%A7%A3%E6%94%BE%E6%80%A7%E4%B8%8E%E5%BC%80%E6%94%BE%E6%80%A7/" title="对chatgpt的欢呼是人对异化的反抗——论ai代写论文的解放性与开放性">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">对chatgpt的欢呼是人对异化的反抗——论ai代写论文的解放性与开放性</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/02/17/%E5%8D%9A%E5%BC%88%E8%AE%BA/" title="博弈论-课程笔记">
                        <span class="hidden-mobile">博弈论-课程笔记</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
</html>
