<!DOCTYPE html>
<html lang=zh>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="renderer" content="webkit">
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="format-detection" content="telephone=no,email=no,adress=no">
  <!-- Color theme for statusbar -->
  <meta name="theme-color" content="#000000" />
  <!-- 强制页面在当前窗口以独立页面显示,防止别人在框架里调用页面 -->
  <meta http-equiv="window-target" content="_top" />
  
  
  <title>机器学习-课程笔记 | Hiryan的世界</title>
  <meta name="description" content="Lecture1_IntroductionApplicationsMachine Learning is all around us Game AI Deep blue, IBM AlphaGo, Deep Mind Deepstack, CMU &amp; Facebook AI   Robot SpotMini, BostonDynamics Big Dog   Image recogniti">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习-课程笔记">
<meta property="og:url" content="http://hiryan23.github.io/2023/02/17/Machine%20Learning/index.html">
<meta property="og:site_name" content="Hiryan的世界">
<meta property="og:description" content="Lecture1_IntroductionApplicationsMachine Learning is all around us Game AI Deep blue, IBM AlphaGo, Deep Mind Deepstack, CMU &amp; Facebook AI   Robot SpotMini, BostonDynamics Big Dog   Image recogniti">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://hiryan23.github.io/pic/9538373a69fb3836595f01495607834.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/bfec802ec5619a7f6b5ef92fd832d31.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/6cf69ccc0b5e18ab05c080df1515205.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/110a43955525c0ad9a62c039eb3876a.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/dce728e8f2d0819688a148ebaf686f9.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/11af398aea2369112afe0fe46f5d255.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/379ac1b116f3c5612b0e6a1f3df25ea.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/b885ffb38cf90c077ad79abb079e005.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/57c1cdf60aceade4f79afcdcf5781c5.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/b9432d6edc99c82146c5ca340b6fd65.png">
<meta property="og:image" content="http://hiryan23.github.io/pic/8c43075b2094ec2db8c526f1ea28d14.png">
<meta property="article:published_time" content="2023-02-17T15:12:03.271Z">
<meta property="article:modified_time" content="2023-02-28T11:43:54.272Z">
<meta property="article:author" content="Ruiyang He">
<meta property="article:tag" content="笔记">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://hiryan23.github.io/pic/9538373a69fb3836595f01495607834.png">
  <!-- Canonical links -->
  <link rel="canonical" href="http://hiryan23.github.io/2023/02/17/Machine%20Learning/index.html">
  
    <link rel="alternate" href="/atom.xml" title="Hiryan的世界" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png" type="image/x-icon">
  
  
<link rel="stylesheet" href="/css/style.css">

  
  
  
  
<meta name="generator" content="Hexo 6.3.0"></head>


<body class="main-center theme-black" itemscope itemtype="http://schema.org/WebPage">
  <header class="header" itemscope itemtype="http://schema.org/WPHeader">
  <div class="slimContent">
    <div class="navbar-header">
      
      
      <div class="profile-block text-center">
        <a id="avatar" href="" target="_blank">
          <img class="img-circle img-rotate" src="/images/avatar.jpg" width="200" height="200">
        </a>
        <h2 id="name" class="hidden-xs hidden-sm">Ruiyang He</h2>
        <h3 id="title" class="hidden-xs hidden-sm hidden-md">上海交通大学 本科生</h3>
        <small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i> Shanghai, China</small>
      </div>
      
      <div class="search" id="search-form-wrap">

    <form class="search-form sidebar-form">
        <div class="input-group">
            <input type="text" class="search-form-input form-control" placeholder="搜索" />
            <span class="input-group-btn">
                <button type="submit" class="search-form-submit btn btn-flat" onclick="return false;"><i class="icon icon-search"></i></button>
            </span>
        </div>
    </form>
    <div class="ins-search">
  <div class="ins-search-mask"></div>
  <div class="ins-search-container">
    <div class="ins-input-wrapper">
      <input type="text" class="ins-search-input" placeholder="想要查找什么..." x-webkit-speech />
      <button type="button" class="close ins-close ins-selectable" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
    </div>
    <div class="ins-section-wrapper">
      <div class="ins-section-container"></div>
    </div>
  </div>
</div>


</div>
      <button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation">
      <ul class="nav navbar-nav main-nav menu-highlight">
        
        
        <li class="menu-item menu-item-home">
          <a href="/.">
            
            <i class="icon icon-home-fill"></i>
            
            <span class="menu-title">首页</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-archives">
          <a href="/archives">
            
            <i class="icon icon-archives-fill"></i>
            
            <span class="menu-title">归档</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-categories">
          <a href="/categories">
            
            <i class="icon icon-folder"></i>
            
            <span class="menu-title">分类</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-tags">
          <a href="/tags">
            
            <i class="icon icon-tags"></i>
            
            <span class="menu-title">标签</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-links">
          <a href="/links">
            
            <i class="icon icon-friendship"></i>
            
            <span class="menu-title">友链</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-about">
          <a href="/about">
            
            <i class="icon icon-cup-fill"></i>
            
            <span class="menu-title">关于</span>
          </a>
        </li>
        
      </ul>
      
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/hiryan23" target="_blank" title="Github" data-toggle=tooltip data-placement=top><i class="icon icon-github"></i></a></li>
        
    </ul>

    </nav>
  </div>
</header>

  
    <aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    
      <div class="widget">
    <h3 class="widget-title">公告</h3>
    <div class="widget-body">
        <div id="board">
            <div class="content">
                <p>你永远不该评判自己不了解的事物。</p>
            </div>
        </div>
    </div>
</div>

    
      
  <div class="widget">
    <h3 class="widget-title">分类</h3>
    <div class="widget-body">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/2022S%E5%8D%9A%E5%BC%88%E8%AE%BA/">2022S博弈论</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/2022S%E5%8F%91%E5%B1%95%E7%BB%8F%E6%B5%8E%E5%AD%A6/">2022S发展经济学</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/2022S%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">2022S机器学习</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/2022S%E8%AE%A1%E9%87%8F%E7%BB%8F%E6%B5%8E%E5%AD%A6/">2022S计量经济学</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/2022S%E8%B4%A2%E5%8A%A1%E7%AE%A1%E7%90%86/">2022S财务管理</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/2022S%E8%B4%A7%E5%B8%81%E9%87%91%E8%9E%8D%E5%AD%A6/">2022S货币金融学</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/2022S%E9%87%91%E8%9E%8D%E5%AD%A6%E5%8E%9F%E7%90%86/">2022S金融学原理</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/2023S%E9%A9%AC%E5%85%8B%E6%80%9D%E4%B8%BB%E4%B9%89%E5%8E%9F%E7%90%86/">2023S马克思主义原理</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%88%86%E4%BA%AB%E6%96%87%E7%AB%A0/">分享文章</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%97%A5%E8%AE%B0%E3%80%81%E6%9D%82%E6%84%9F%E4%B8%8E%E8%87%AA%E6%88%91%E6%89%B9%E5%88%A4/">日记、杂感与自我批判</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9D%82/">杂</a><span class="category-list-count">1</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">标签</h3>
    <div class="widget-body">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E2%80%9C%E6%84%8F%E8%AF%86%E6%B5%81%E2%80%9D/" rel="tag">“意识流”</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8F%91%E5%B1%95%E7%BB%8F%E6%B5%8E%E5%AD%A6/" rel="tag">发展经济学</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%90%8E%E7%8E%B0%E4%BB%A3%E4%B8%BB%E4%B9%89%E5%93%B2%E5%AD%A6/" rel="tag">后现代主义哲学</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AE%8F%E8%A7%82%E9%87%91%E8%9E%8D%E5%AD%A6/" rel="tag">宏观金融学</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B0%8F%E8%AF%B4-%E6%95%A3%E6%96%87%E7%AD%89/" rel="tag">小说\散文等</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BE%AE%E8%A7%82%E7%BB%8F%E6%B5%8E%E5%AD%A6/" rel="tag">微观经济学</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BE%AE%E8%A7%82%E9%87%91%E8%9E%8D%E5%AD%A6/" rel="tag">微观金融学</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B1%BD%E8%BD%A6%E6%8E%A7%E5%88%B6/" rel="tag">汽车控制</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%A4%BE%E4%BC%9A%E5%88%86%E6%9E%90/" rel="tag">社会分析</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AC%94%E8%AE%B0/" rel="tag">笔记</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%A1%E9%87%8F%E7%BB%8F%E6%B5%8E%E5%AD%A6/" rel="tag">计量经济学</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%87%91%E8%9E%8D%E5%AD%A6/" rel="tag">金融学</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%A9%AC%E5%8E%9F/" rel="tag">马原</a><span class="tag-list-count">1</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">标签云</h3>
    <div class="widget-body tagcloud">
      <a href="/tags/%E2%80%9C%E6%84%8F%E8%AF%86%E6%B5%81%E2%80%9D/" style="font-size: 13px;">“意识流”</a> <a href="/tags/%E5%8F%91%E5%B1%95%E7%BB%8F%E6%B5%8E%E5%AD%A6/" style="font-size: 13px;">发展经济学</a> <a href="/tags/%E5%90%8E%E7%8E%B0%E4%BB%A3%E4%B8%BB%E4%B9%89%E5%93%B2%E5%AD%A6/" style="font-size: 13px;">后现代主义哲学</a> <a href="/tags/%E5%AE%8F%E8%A7%82%E9%87%91%E8%9E%8D%E5%AD%A6/" style="font-size: 13px;">宏观金融学</a> <a href="/tags/%E5%B0%8F%E8%AF%B4-%E6%95%A3%E6%96%87%E7%AD%89/" style="font-size: 13px;">小说\散文等</a> <a href="/tags/%E5%BE%AE%E8%A7%82%E7%BB%8F%E6%B5%8E%E5%AD%A6/" style="font-size: 13px;">微观经济学</a> <a href="/tags/%E5%BE%AE%E8%A7%82%E9%87%91%E8%9E%8D%E5%AD%A6/" style="font-size: 13px;">微观金融学</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 13px;">机器学习</a> <a href="/tags/%E6%B1%BD%E8%BD%A6%E6%8E%A7%E5%88%B6/" style="font-size: 13px;">汽车控制</a> <a href="/tags/%E7%A4%BE%E4%BC%9A%E5%88%86%E6%9E%90/" style="font-size: 13px;">社会分析</a> <a href="/tags/%E7%AC%94%E8%AE%B0/" style="font-size: 14px;">笔记</a> <a href="/tags/%E8%AE%A1%E9%87%8F%E7%BB%8F%E6%B5%8E%E5%AD%A6/" style="font-size: 13px;">计量经济学</a> <a href="/tags/%E9%87%91%E8%9E%8D%E5%AD%A6/" style="font-size: 13px;">金融学</a> <a href="/tags/%E9%A9%AC%E5%8E%9F/" style="font-size: 13px;">马原</a>
    </div>
  </div>

    
      
  <div class="widget">
    <h3 class="widget-title">归档</h3>
    <div class="widget-body">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/02/">二月 2023</a><span class="archive-list-count">13</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget-body">
      <ul class="recent-post-list list-unstyled no-thumbnail">
        
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E5%88%86%E4%BA%AB%E6%96%87%E7%AB%A0/">分享文章</a>
              </p>
              <p class="item-title">
                <a href="/2023/02/28/%E6%9C%80%E5%90%8E%E4%B8%80%E5%90%8D/" class="title">最后一名 | 马塞尔·埃梅</a>
              </p>
              <p class="item-date">
                <time datetime="2023-02-28T13:04:05.126Z" itemprop="datePublished">2023-02-28</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/2023S%E9%A9%AC%E5%85%8B%E6%80%9D%E4%B8%BB%E4%B9%89%E5%8E%9F%E7%90%86/">2023S马克思主义原理</a>
              </p>
              <p class="item-title">
                <a href="/2023/02/27/%E9%A9%AC%E5%85%8B%E6%80%9D%E4%B8%BB%E4%B9%89%E5%8E%9F%E7%90%86/" class="title">马克思主义原理-重点梳理</a>
              </p>
              <p class="item-date">
                <time datetime="2023-02-27T06:20:15.125Z" itemprop="datePublished">2023-02-27</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E6%9D%82/">杂</a>
              </p>
              <p class="item-title">
                <a href="/2023/02/22/%E4%B8%80%E9%81%93can%E6%8A%A5%E6%96%87%E8%AF%BB%E5%8F%96%E7%9A%84%E9%97%AE%E9%A2%98/" class="title">一道can报文读取的问题</a>
              </p>
              <p class="item-date">
                <time datetime="2023-02-22T05:44:19.256Z" itemprop="datePublished">2023-02-22</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E6%97%A5%E8%AE%B0%E3%80%81%E6%9D%82%E6%84%9F%E4%B8%8E%E8%87%AA%E6%88%91%E6%89%B9%E5%88%A4/">日记、杂感与自我批判</a>
              </p>
              <p class="item-title">
                <a href="/2023/02/22/2023.02.22/" class="title">2023.02.22</a>
              </p>
              <p class="item-date">
                <time datetime="2023-02-22T00:14:36.308Z" itemprop="datePublished">2023-02-22</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E5%88%86%E4%BA%AB%E6%96%87%E7%AB%A0/">分享文章</a>
              </p>
              <p class="item-title">
                <a href="/2023/02/19/%E5%AF%B9chatgpt%E7%9A%84%E6%AC%A2%E5%91%BC%E6%98%AF%E4%BA%BA%E5%AF%B9%E5%BC%82%E5%8C%96%E7%9A%84%E5%8F%8D%E6%8A%97%E2%80%94%E2%80%94%E8%AE%BAai%E4%BB%A3%E5%86%99%E8%AE%BA%E6%96%87%E7%9A%84%E8%A7%A3%E6%94%BE%E6%80%A7%E4%B8%8E%E5%BC%80%E6%94%BE%E6%80%A7/" class="title">对chatgpt的欢呼是人对异化的反抗——论ai代写论文的解放性与开放性</a>
              </p>
              <p class="item-date">
                <time datetime="2023-02-19T12:27:55.196Z" itemprop="datePublished">2023-02-19</time>
              </p>
            </div>
          </li>
          
      </ul>
    </div>
  </div>
  

    
  </div>
</aside>

  
  
  <aside class="sidebar sidebar-toc   in  " id="collapseToc" itemscope
    itemtype="http://schema.org/WPSideBar">
    <div class="slimContent">
      <nav id="toc" class="article-toc">
        <h3 class="toc-title">
          文章目录
        </h3>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Lecture1-Introduction"><span class="toc-text">Lecture1_Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Applications"><span class="toc-text">Applications</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Machine-Learning-is-all-around-us"><span class="toc-text">Machine Learning is all around us</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Economical-impact-of-Machine-Learning"><span class="toc-text">Economical impact of Machine Learning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Trends-of-Machine-Learning"><span class="toc-text">Trends of Machine Learning</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Definition"><span class="toc-text">Definition</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#What-is-Machine-Learning"><span class="toc-text">What is Machine Learning?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Programming-vs-Machine-Learning"><span class="toc-text">Programming vs Machine Learning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Brief-History-of-Machine-Learning"><span class="toc-text">Brief History of Machine Learning</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Categories"><span class="toc-text">Categories</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Supervised-Learning"><span class="toc-text">Supervised Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Process-of-Supervised-Learning"><span class="toc-text">Process of Supervised Learning</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Unsupervised-Learning"><span class="toc-text">Unsupervised Learning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Some-Machine-Learning-algorithms"><span class="toc-text">Some Machine Learning algorithms</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Lecture2-MathForML"><span class="toc-text">Lecture2_MathForML</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Notations"><span class="toc-text">Notations</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Probability-amp-Statistics"><span class="toc-text">Probability &amp; Statistics</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Sample-space-Omega"><span class="toc-text">Sample space($\Omega$)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Event-E"><span class="toc-text">Event($E$)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Event-space-mathcal-F"><span class="toc-text">Event space($\mathcal F$)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Axioms-of-probability"><span class="toc-text">Axioms of probability</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Random-variable-RV"><span class="toc-text">Random variable (RV)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Probability-distribution"><span class="toc-text">Probability distribution</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Joint-distribution"><span class="toc-text">Joint distribution</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Conditional-probability"><span class="toc-text">Conditional probability</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Product-rule"><span class="toc-text">Product rule</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Bayes%E2%80%99-rule"><span class="toc-text">Bayes’ rule</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Marginal-probability"><span class="toc-text">Marginal probability</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Independence"><span class="toc-text">Independence</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Expectation"><span class="toc-text">Expectation</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Conditional-expectation"><span class="toc-text">Conditional expectation</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Law-of-total-expectation"><span class="toc-text">Law of total expectation</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Variance"><span class="toc-text">Variance</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Covariance"><span class="toc-text">Covariance</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Estimation-of-Parameters"><span class="toc-text">Estimation of Parameters</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Maximum-Likelihood-Estimation-MLE"><span class="toc-text">Maximum Likelihood Estimation (MLE)</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#Example-of-MLE"><span class="toc-text">Example of MLE</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Maximum-A-Posteriori-Estimation-MAP"><span class="toc-text">Maximum A Posteriori Estimation (MAP)</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#Example-of-MAP"><span class="toc-text">Example of MAP</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Linear-Algebra"><span class="toc-text">Linear Algebra</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Vector"><span class="toc-text">Vector</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Matrix"><span class="toc-text">Matrix</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Vector-algorithmic"><span class="toc-text">Vector algorithmic</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Vector-norm"><span class="toc-text">Vector norm</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Matrix-arithmetric"><span class="toc-text">Matrix arithmetric</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Transpose"><span class="toc-text">Transpose</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Symmetric-matrix"><span class="toc-text">Symmetric matrix</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Inverse-of-a-matrix"><span class="toc-text">Inverse of a matrix</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Semidefinite-matrices"><span class="toc-text">Semidefinite matrices</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Back-to-Probability-amp-Statistics"><span class="toc-text">Back to Probability &amp; Statistics</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Random-vector"><span class="toc-text">Random vector</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Covariance-matrix"><span class="toc-text">Covariance matrix</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Matrix-calculus"><span class="toc-text">Matrix calculus</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Optimization"><span class="toc-text">Optimization</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#What-is-optimization"><span class="toc-text">What is optimization?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Local-minima-and-global-minima"><span class="toc-text">Local minima and global minima</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Convex-set"><span class="toc-text">Convex set</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Convex-Concave-function"><span class="toc-text">Convex (Concave) function</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#First-order-convexity-condition"><span class="toc-text">First-order convexity condition</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Second-order-convexity-condition"><span class="toc-text">Second-order convexity condition</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Examples-of-convex-functions"><span class="toc-text">Examples of convex functions</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Convex-optimization-problem"><span class="toc-text">Convex optimization problem</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#It%E2%80%99s-nice-to-be-convex"><span class="toc-text">It’s nice to be convex!</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Optimization-methods"><span class="toc-text">Optimization methods</span></a></li></ol></li></ol></li></ol>
      </nav>
    </div>
  </aside>
  
<main class="main" role="main">
  <div class="content">
  <article id="post-Machine Learning" class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting">
    
    <div class="article-header">
      
        
    
          <h1 class="article-title" itemprop="name">
            机器学习-课程笔记
          </h1>
          
            
      
      <div class="article-meta">
        <span class="article-date">
	<i class="icon icon-calendar"></i>
	<a href="/2023/02/17/Machine%20Learning/" class="article-date">
		<time datetime="2023-02-17T15:12:03.271Z" itemprop="datePublished">
			2023-02-17
		</time>
	</a>
</span>

<span class="article-date">
	<i class="icon icon-calendar-check"></i>
	<a href="/2023/02/17/Machine%20Learning/" class="article-date">
		<time datetime="2023-02-28T11:43:54.272Z" itemprop="dateUpdated">
			2023-02-28
		</time>
	</a>
</span>
        
  <span class="article-category">
    <i class="icon icon-folder"></i>
    <a class="article-category-link" href="/categories/2022S%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">2022S机器学习</a>
  </span>

        
  <span class="article-tag">
    <i class="icon icon-tags"></i>
	<a class="article-tag-link-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a>, <a class="article-tag-link-link" href="/tags/%E7%AC%94%E8%AE%B0/" rel="tag">笔记</a>
  </span>


        
	<span class="article-read hidden-xs">
		<i class="icon icon-eye-fill" aria-hidden="true"></i>
		<span id="busuanzi_container_page_pv">
			<span id="busuanzi_value_page_pv"></span>
		</span>
	</span>

	
		
        <span class="post-comment"><i class="icon icon-comment"></i> <a href="/2023/02/17/Machine%20Learning/#comments" class="article-comment-link">评论</a></span>
        
      </div>
    </div>
    <div class="article-entry marked-body" itemprop="articleBody">
      
        <h2 id="Lecture1-Introduction"><a href="#Lecture1-Introduction" class="headerlink" title="Lecture1_Introduction"></a>Lecture1_Introduction</h2><h3 id="Applications"><a href="#Applications" class="headerlink" title="Applications"></a>Applications</h3><h4 id="Machine-Learning-is-all-around-us"><a href="#Machine-Learning-is-all-around-us" class="headerlink" title="Machine Learning is all around us"></a>Machine Learning is all around us</h4><ul>
<li>Game AI<ul>
<li>Deep blue, IBM</li>
<li>AlphaGo, Deep Mind</li>
<li>Deepstack, CMU &amp; Facebook AI</li>
</ul>
</li>
<li>Robot<ul>
<li>SpotMini, BostonDynamics</li>
<li>Big Dog</li>
</ul>
</li>
<li>Image recognition</li>
<li>Self-driving car</li>
<li>Medical Diagnosis</li>
<li>Applications of ML in business settings</li>
<li>Customer segmentation</li>
<li>Applications in Finance</li>
<li>Credit lending &amp; Fraud detection</li>
<li>Personalized recommendation</li>
<li>Dynamic pricing<ul>
<li>Rue La La</li>
</ul>
</li>
<li>Order dispatch for ride-sharing platforms<ul>
<li>DiDi</li>
</ul>
</li>
</ul>
<h4 id="Economical-impact-of-Machine-Learning"><a href="#Economical-impact-of-Machine-Learning" class="headerlink" title="Economical impact of Machine Learning"></a>Economical impact of Machine Learning</h4><ul>
<li>By 2035, AI could double annual global economic growth rates (Accenture)</li>
<li>Global GDP may increase by up to 14% (the equivalent of US$15.7 trillion) by 2030 as a result of the accelerating development and take-up of AI (PwC)</li>
</ul>
<h4 id="Trends-of-Machine-Learning"><a href="#Trends-of-Machine-Learning" class="headerlink" title="Trends of Machine Learning"></a>Trends of Machine Learning</h4><p><img src="/pic/9538373a69fb3836595f01495607834.png" alt="Trends of ML"></p>
<h3 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h3><h4 id="What-is-Machine-Learning"><a href="#What-is-Machine-Learning" class="headerlink" title="What is Machine Learning?"></a>What is Machine Learning?</h4><ul>
<li>Field of study that gives computers the ability to learn without being explicitly programmed. - Arthur Samuel, 1959</li>
<li>A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E. - Tom Mitchell, 1997</li>
</ul>
<h4 id="Programming-vs-Machine-Learning"><a href="#Programming-vs-Machine-Learning" class="headerlink" title="Programming vs Machine Learning"></a>Programming vs Machine Learning</h4><p><img src="/pic/bfec802ec5619a7f6b5ef92fd832d31.png" alt="Programming vs ML"></p>
<h4 id="Brief-History-of-Machine-Learning"><a href="#Brief-History-of-Machine-Learning" class="headerlink" title="Brief History of Machine Learning"></a>Brief History of Machine Learning</h4><ol>
<li>Connectionism, 1950s<ul>
<li>Perception, F. Rosenblatt</li>
</ul>
</li>
<li>Checker game, Arthur Samuel, 1959<ul>
<li>The term Machine Learning is coined.</li>
</ul>
</li>
<li>Symbolism, 1970-1980s<ul>
<li>Decision tree</li>
<li>ID3, Quinlan</li>
<li>Classification and Regression Tree (CART)</li>
</ul>
</li>
<li>Connectionism, 1980-1990s<ul>
<li>Back-Propagation</li>
<li>for Multi-layer Neural Networks</li>
</ul>
</li>
<li>Statistical Learning, 1990s<ul>
<li>Support vector machine</li>
<li>Kernel methods</li>
</ul>
</li>
<li>Connectionism, 2000s<ul>
<li>Deep Learning</li>
</ul>
</li>
</ol>
<h3 id="Categories"><a href="#Categories" class="headerlink" title="Categories"></a>Categories</h3><p>Categories of Machine Learning<br><img src="/pic/6cf69ccc0b5e18ab05c080df1515205.png" alt="Categories of ML"></p>
<h4 id="Supervised-Learning"><a href="#Supervised-Learning" class="headerlink" title="Supervised Learning"></a>Supervised Learning</h4><p><img src="/pic/110a43955525c0ad9a62c039eb3876a.png" alt="SL"></p>
<ul>
<li>Aims to <strong>predict on unknown data</strong> using models trained by labeled data</li>
<li>Learning a function that maps the <strong>feature (attribute)</strong> to <strong>label (response)</strong></li>
<li>Classification vs Regression<ul>
<li>Both utilize the training set (known data) to make predictions</li>
<li>The output of classification is categorical (<strong>discrete</strong>) while the output of regression is numerical (<strong>continuous</strong>)</li>
</ul>
</li>
</ul>
<h5 id="Process-of-Supervised-Learning"><a href="#Process-of-Supervised-Learning" class="headerlink" title="Process of Supervised Learning"></a>Process of Supervised Learning</h5><ol>
<li>Split data into training &amp; test sets</li>
<li>Train a model</li>
<li>Make predictions on testing set</li>
<li>Compare predicted and true labels</li>
</ol>
<h4 id="Unsupervised-Learning"><a href="#Unsupervised-Learning" class="headerlink" title="Unsupervised Learning"></a>Unsupervised Learning</h4><p><img src="/pic/dce728e8f2d0819688a148ebaf686f9.png" alt="UL"></p>
<p>Discover the structure and pattern within the unlabeled data.</p>
<ul>
<li>Market Segmentation</li>
<li>Social Network Analysis</li>
</ul>
<h4 id="Some-Machine-Learning-algorithms"><a href="#Some-Machine-Learning-algorithms" class="headerlink" title="Some Machine Learning algorithms"></a>Some Machine Learning algorithms</h4><p><img src="/pic/11af398aea2369112afe0fe46f5d255.png" alt="ML algorithms"></p>
<h2 id="Lecture2-MathForML"><a href="#Lecture2-MathForML" class="headerlink" title="Lecture2_MathForML"></a>Lecture2_MathForML</h2><h4 id="Notations"><a href="#Notations" class="headerlink" title="Notations"></a>Notations</h4><ul>
<li>$a \in A$ : $a$ is a member of set A</li>
<li>$||\pmb{v}||$ : the norm of vector $\pmb{v}$</li>
<li>$\pmb{x},\pmb{y},\pmb{z}$ : vector (lower case, bold)</li>
<li>$\pmb{A},\pmb{B}$ : matrix (upper case, bold)</li>
<li>$X$ : random variable (upper case)</li>
<li>$x$ : realizaton of random variable (lower case)</li>
<li>$y&#x3D; f(\pmb{x})$ : function with muitiple inputs</li>
</ul>
<h3 id="Probability-amp-Statistics"><a href="#Probability-amp-Statistics" class="headerlink" title="Probability &amp; Statistics"></a>Probability &amp; Statistics</h3><h4 id="Sample-space-Omega"><a href="#Sample-space-Omega" class="headerlink" title="Sample space($\Omega$)"></a>Sample space($\Omega$)</h4><p>Set of all possible outcomes of an experiment</p>
<h4 id="Event-E"><a href="#Event-E" class="headerlink" title="Event($E$)"></a>Event($E$)</h4><p>Any subset of outcomes contained in the sample space</p>
<h4 id="Event-space-mathcal-F"><a href="#Event-space-mathcal-F" class="headerlink" title="Event space($\mathcal F$)"></a>Event space($\mathcal F$)</h4><p>The set of all possible events</p>
<h4 id="Axioms-of-probability"><a href="#Axioms-of-probability" class="headerlink" title="Axioms of probability"></a>Axioms of probability</h4><p>The <em>probabililty distribution</em> P is a function that satisfies the following</p>
<ol>
<li>$0 \leq P(E) \leq 1$ for any $E \in \mathcal F$ (Non-negativity)</li>
<li>$P(\Omega)&#x3D;1$ </li>
<li>$P(E_1 \cup E_2)&#x3D;P(E_1)+P(E_2)$ if $E_1$ and $E_2$ mutually exclusive events (Additivity)</li>
</ol>
<h4 id="Random-variable-RV"><a href="#Random-variable-RV" class="headerlink" title="Random variable (RV)"></a>Random variable (RV)</h4><p>mapping from sample space to real numbers</p>
<ul>
<li>Probability distribution specifies the probability of observing every possible value of a random variable</li>
<li>Discrete RV has a countable set of possible values: Bernoulli, Poisson, …</li>
<li>Continuous RV can take infinitely many possible values: Uniform, Normal, Exponential, …</li>
</ul>
<h4 id="Probability-distribution"><a href="#Probability-distribution" class="headerlink" title="Probability distribution"></a>Probability distribution</h4><p>Cumulative distribution function (CDF)<br>$$ F_X(x)&#x3D;P(X \leq x)$$<br>Discrete random variable: probability mass function $p_X(x)$<br>$$p_X(x)&#x3D;P(X&#x3D;x)$$<br>Continuous random variable: probability density function $f_X(x)$<br>$$f_X(x) &#x3D; \cfrac{\text{d}F_X(x)}{\text{d}x}$$</p>
<h4 id="Joint-distribution"><a href="#Joint-distribution" class="headerlink" title="Joint distribution"></a>Joint distribution</h4><p>Consider two random variables $X$ and $Y$ , the <em>joint cumulative distribution function</em> is defined as<br>$$F_{XY}(x,y)&#x3D;P(X \leq x,Y \leq y)$$<br>The joint probability mass function of two discrete variables $X$ , $Y$<br>$$p_{X,Y}(x,y)&#x3D;P(X&#x3D;x,Y&#x3D;y)$$<br>The joint probability density function of two continuous variables $X$ , $Y$<br>$$f_{X,Y}(x,y)&#x3D;\cfrac{\partial^2 F_{XY}(x,y)}{\partial x \partial y}$$</p>
<h4 id="Conditional-probability"><a href="#Conditional-probability" class="headerlink" title="Conditional probability"></a>Conditional probability</h4><p>The conditional probability of $X$ given $Y&#x3D;y$ is defined as,<br>$$P(X&#x3D;x|Y&#x3D;y)&#x3D;\cfrac{P(X&#x3D;x,Y&#x3D;y)}{P(Y&#x3D;y)}$$</p>
<h4 id="Product-rule"><a href="#Product-rule" class="headerlink" title="Product rule"></a>Product rule</h4><p>$$P(X&#x3D;x,Y&#x3D;y)&#x3D;P(X&#x3D;x|Y&#x3D;y)P(Y&#x3D;y)&#x3D;P(Y&#x3D;y|X&#x3D;x)P(X&#x3D;x)$$</p>
<h4 id="Bayes’-rule"><a href="#Bayes’-rule" class="headerlink" title="Bayes’ rule"></a>Bayes’ rule</h4><p>$$P(Y&#x3D;y|X&#x3D;x)&#x3D;\cfrac{P(X&#x3D;x|Y&#x3D;y)\cdot P(Y&#x3D;y)}{P(X&#x3D;x)}$$</p>
<ul>
<li>Application: SPAM email case<ul>
<li>y: labels (SPAM&#x2F;normal)</li>
<li>x: frequency of keywords</li>
</ul>
</li>
</ul>
<p>	</p>
<h4 id="Marginal-probability"><a href="#Marginal-probability" class="headerlink" title="Marginal probability"></a>Marginal probability</h4><p>The probability of event that will occur regardless of conditional events<br>$$<br>\begin{align}<br>P(X&#x3D;x) &amp;&#x3D; \sum_{y \in \mathcal{y}}P(X&#x3D;x,Y&#x3D;y) \<br>       &amp;&#x3D; \sum_{y \in \mathcal{y}}P(X&#x3D;x|Y&#x3D;y)P(Y&#x3D;y)<br>\end{align}<br>$$</p>
<h4 id="Independence"><a href="#Independence" class="headerlink" title="Independence"></a>Independence</h4><p>Consider two events $A$ and $B$ , they are <em>independent</em>  if<br>$$<br>P(X&#x3D;x,Y&#x3D;y)&#x3D;P(X&#x3D;x) \cdot P(Y&#x3D;y)<br>$$<br>In addition, (if they are independent: )<br>$$<br>P(X&#x3D;x)&#x3D; \cfrac{P(X&#x3D;x,Y&#x3D;y)}{P(Y&#x3D;y)}&#x3D;P(X&#x3D;x | Y&#x3D;y)<br>$$</p>
<h4 id="Expectation"><a href="#Expectation" class="headerlink" title="Expectation"></a>Expectation</h4><p>Expectation (expected value) of a random variable $X$ is computed as</p>
<ul>
<li><u>Discrete RV</u> $$ \mathbb{E} [x] &#x3D; \sum_x x \cdot p(x)$$</li>
<li><u>Continuous RV</u> $$ \mathbb{E}[X]&#x3D;\int_x x \cdot f(x) \cdot \text{d} x$$</li>
<li>Expectation of functions $$\mathbb{E}[h(X)] &#x3D; \int_x h(x) \cdot  f(x) \cdot \text{d}x$$</li>
<li>Other properties: $$\begin{align}<br>\mathbb{E}[aX+b]&amp;&#x3D;a\mathbb{E}[X]+b \<br>\mathbb{E}[X+Y]&amp;&#x3D;\mathbb{E}[X]+\mathbb{E}[Y]\<br>\mathbb E[XY]&amp;&#x3D;\mathbb E[X]\mathbb E[Y],\ \text{if\ X\ and\ Y\ are uncoorrelated}<br>\end{align}$$</li>
</ul>
<h4 id="Conditional-expectation"><a href="#Conditional-expectation" class="headerlink" title="Conditional expectation"></a>Conditional expectation</h4><p>The conditional expectation of $X$ with respect to $Y$ is the function<br>$$\mathbb{E}[X|Y&#x3D;y]$$<br>Discrete random variable<br>$$\mathbb{E}[X|Y&#x3D;y]&#x3D; \sum_x x\cdot P(X&#x3D;x|Y&#x3D;y)$$<br>Continuous random variable<br>$$ \mathbb{E}[X|Y&#x3D;y]&#x3D;\int_x x f_{X|Y}(x|y) \text{d}x$$</p>
<h5 id="Law-of-total-expectation"><a href="#Law-of-total-expectation" class="headerlink" title="Law of total expectation"></a>Law of total expectation</h5><p>$$\mathbb{E}[X] &#x3D; \mathbb{E}[\mathbb{E}[X|Y]]$$</p>
<h4 id="Variance"><a href="#Variance" class="headerlink" title="Variance"></a>Variance</h4><p>The squared deviation of $X$ from its mean<br>$$ \text{Var}[X]&#x3D;\mathbb{E}[(X-\mathbb{E}[X])^2]&#x3D;\mathbb{E}[X^2]&#x3D;\mathbb{E}[X]^2$$</p>
<ul>
<li>Standard variation $$ \sigma &#x3D; \sqrt{\text{Var}[X]}$$</li>
<li>Other properties $$\begin{align}<br>\text{Var}[aX+b]&amp;&#x3D;a^2 \cdot \text{Var}[x] \<br>\text{Var}[X+Y]&amp;&#x3D;\text{Var}[X]+\text{Var}[Y]\ \text{if X,Y are uncorrelated}<br>\end{align}$$</li>
</ul>
<h4 id="Covariance"><a href="#Covariance" class="headerlink" title="Covariance"></a>Covariance</h4><p>$$ \text{Cov}(X_1,X_2)&#x3D;\mathbb{E}[(X_1-\mathbb{E}[X_1])(X_2-\mathbb{E}[X_2])]$$</p>
<h4 id="Estimation-of-Parameters"><a href="#Estimation-of-Parameters" class="headerlink" title="Estimation of Parameters"></a>Estimation of Parameters</h4><ul>
<li>Suppose we have random variables $X_1, X_2, \cdots, X_n$ and corresponding observations $x_1, x_2, \cdots, x_n$</li>
<li>We select a parametric model and fit the parameters of the model to the data.</li>
<li>How do we choose the values of the parameters $\theta$ ?</li>
</ul>
<h5 id="Maximum-Likelihood-Estimation-MLE"><a href="#Maximum-Likelihood-Estimation-MLE" class="headerlink" title="Maximum Likelihood Estimation (MLE)"></a>Maximum Likelihood Estimation (MLE)</h5><p>Which $\theta$ makes the observations $x_1,x_2,\cdots,x_n$ most likely?</p>
<ul>
<li>Maximize the likelihood of the observed data $$ \hat{\theta}_{MLE}&#x3D;\text{arg}\max_\theta \mathcal{L}(\theta)&#x3D;\text{arg}\max_\theta p(x_1,x_2,\cdots,x_n|\theta)$$</li>
<li>Assume that $x_1,x_2, \cdots,x_n$ are i.i.d., we have $$\mathcal{L}(\theta)&#x3D;\prod_{i&#x3D;1}^n p(x_i|\theta)$$</li>
<li>Take the logarithmic on both sides, we obtain the log-likelihood $$\log \mathcal{L}(\theta)&#x3D; \sum_{i&#x3D;1}^n \log p(x_i|\theta)$$</li>
</ul>
<h6 id="Example-of-MLE"><a href="#Example-of-MLE" class="headerlink" title="Example of MLE"></a>Example of MLE</h6><ul>
<li>Imagine a bowl contains a large number of red and white balls. The proportion of the red balls, denoted by $\theta$ , is unknown.</li>
<li>Now we sample balls from this bowl with replacement for $n$ times and observe $x$ red balls out of $n$ balls.</li>
<li>Likelihood function:$$\begin{align}<br>L(\theta)&#x3D;L(x;\theta)&#x3D;\binom{n}{x}\theta^x(1-\theta)^{n-x} \<br>\log L(\theta) &#x3D; x\log \theta+(n-x)\log(1-\theta) \<br>\cfrac{\partial \log L(\theta)}{\partial \theta} &#x3D; 0 \Rightarrow \hat\theta_{MLE} &#x3D; \cfrac{x}{n}<br>\end{align}$$</li>
</ul>
<h5 id="Maximum-A-Posteriori-Estimation-MAP"><a href="#Maximum-A-Posteriori-Estimation-MAP" class="headerlink" title="Maximum A Posteriori Estimation (MAP)"></a>Maximum A Posteriori Estimation (MAP)</h5><p>Which $\theta$ maximizes the posterior $p(\theta | x_1,x_2,\cdots,x_n)$ given the prior $p(\theta)$ ?</p>
<ul>
<li>We assume that the parameter is a random variable, and we specify a prior distribution $p(\theta)$</li>
<li>By Bayes’ rule, we compute the posterior of the parameter $$p(\theta | x_1,x_2,\cdots,x_n) \propto p(\theta)p(x_1,x_2,\cdots,x_n|\theta)$$</li>
<li>Estimate parameter $\theta$ by maximizing the posterior $$\hat\theta_{MAP}&#x3D;\text{arg}\max_\theta p(\theta)p(x_1,x_2,\cdots,x_n|\theta)$$</li>
<li>We take the logarithmic of the posterior, $$\hat\theta_{MAP}&#x3D;\text{arg}\max_\theta \log p(\theta)+\sum_{i&#x3D;1}^n \log p(x_i|\theta)$$<br><em>: MAP: balance MLE and prior knowledge</em></li>
</ul>
<h6 id="Example-of-MAP"><a href="#Example-of-MAP" class="headerlink" title="Example of MAP"></a>Example of MAP</h6><ul>
<li>Imagine a bowl contains a large number of red and white balls. The proportion of the red balls, denoted by $\theta$ , is unknown, but with a Beta prior, $P(\theta) &#x3D;\cfrac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1}$</li>
<li>Now we sample balls from this bowl with replacement for $n$ times and observe $x$ red balls out of $n$ balls.</li>
<li>The posterior function: $$\begin{align}<br>p(x|\theta)p(\theta) &amp;&#x3D; \binom{n}{x}\theta^x(1-\theta)^{n-x}\cfrac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1} \<br>\log p(x|\theta)p(\theta) &amp;&#x3D; (x+\alpha-1)\log \theta +(n-x+\beta -1)\log(1-\theta) \<br>\hat\theta_{MAP}&amp;&#x3D;\cfrac{x+\alpha-1}{n+\alpha+\beta-2}<br>\end{align}$$</li>
</ul>
<h3 id="Linear-Algebra"><a href="#Linear-Algebra" class="headerlink" title="Linear Algebra"></a>Linear Algebra</h3><h4 id="Vector"><a href="#Vector" class="headerlink" title="Vector"></a>Vector</h4><ul>
<li>A one-dimension array of $n$ values, denoted by $\pmb{x}$ (lower case, bold)</li>
<li>$x_i$ is the $i$-th element of $\pmb{x}$ $$ \pmb{x}&#x3D;(x_1,x_2,\cdots,x_n)^T&#x3D; \begin{bmatrix}x_1\ x_2\ \vdots \ x_n \end{bmatrix}$$</li>
</ul>
<h4 id="Matrix"><a href="#Matrix" class="headerlink" title="Matrix"></a>Matrix</h4><ul>
<li>A two-dimension array of $m \times n$ values, denoted by $\pmb{A}$ (upper case, bold)</li>
<li>$m$ is the number of row vector, $n$ is the number of column vectors</li>
<li>$a_{ij}$ is the entry in $i$-th row and $j$-th column $$\pmb{A}&#x3D;\begin{bmatrix} a_{11} &amp;\cdots &amp;a_{1n} \ \vdots &amp;\ddots &amp;\vdots \ a_{m1} &amp;\cdots &amp;a_{mn} \end{bmatrix} $$</li>
</ul>
<h4 id="Vector-algorithmic"><a href="#Vector-algorithmic" class="headerlink" title="Vector algorithmic"></a>Vector algorithmic</h4><ul>
<li>Scalar multiplication of a vector $$ \pmb{y}&#x3D;a\pmb{x}&#x3D;(ax_1,ax_2,\cdots,ax_n)^T$$</li>
<li>Dot product of the vectors $\pmb{x},\pmb{y} \in \mathbb{R}^n$ $$\pmb{x}^T\pmb{y} &#x3D; [x_1,x_2,\cdots, x_n]\begin{bmatrix}y_1\ y_2\ \vdots\ y_n\end{bmatrix}&#x3D;\sum_{i&#x3D;1}^n x_iy_i \in \mathbb{R}$$</li>
<li>Outer product of the vectors $\pmb{x} \in \mathbb{R}^m, \pmb{y} \in \mathbb{R}^n$ $$\pmb{x}\pmb{y}^T&#x3D;\begin{bmatrix}x_1\ x_2\ \vdots x_m\end{bmatrix}[y_1,y_2,\cdots,y_n]&#x3D;\begin{bmatrix}x_1y_1 &amp;\cdots &amp;x_1y_n\ \vdots &amp;\ddots &amp;\vdots\ x_my_1 &amp;\cdots &amp;x_my_n\end{bmatrix}$$</li>
</ul>
<h4 id="Vector-norm"><a href="#Vector-norm" class="headerlink" title="Vector norm"></a>Vector norm</h4><p>A norm $||\cdot||$ is a function that satisfies</p>
<ul>
<li>$||\pmb{x}|| \geq 0$ with equality if and only if $\pmb{x}&#x3D;\pmb{0}$</li>
<li>$||\pmb{x}+\pmb{y}|| \leq ||\pmb{x}|| + ||\pmb{y}||$</li>
<li>$||a\pmb{x}||&#x3D;|a|||\pmb{x}||$</li>
<li>$\pmb{x}^T\pmb{y}&#x3D;||\pmb{x}||_2||\pmb{y}||_2\cos(\theta)$</li>
<li>$l_1$ norm $||\pmb{x}||<em>1&#x3D;\displaystyle\sum</em>{i&#x3D;1}^n|x_i|$</li>
<li>$l_2$ norm $||\pmb{x}||<em>2&#x3D;\left(\displaystyle\sum</em>{i&#x3D;1}^n|x_i|^2\right)^{\frac{1}{2}}$</li>
</ul>
<h4 id="Matrix-arithmetric"><a href="#Matrix-arithmetric" class="headerlink" title="Matrix arithmetric"></a>Matrix arithmetric</h4><ul>
<li>Addition of matrices $\pmb{A},\pmb{B} \in \mathbb{R}^{m\times n}$ $$\pmb{C}&#x3D;\pmb{A}+\textcolor{red}{\pmb{B}}&#x3D;\begin{bmatrix} a_{11}+\textcolor{red}{b_{11}} &amp;\cdots &amp;a_{1n}+\textcolor{red}{b_{1n}}\ \vdots &amp;\ddots &amp;\vdots\ a_{m1}+\textcolor{red}{b_{m1}} &amp;\cdots &amp;a_{mn}+\textcolor{red}{b_{mn}} \end{bmatrix}$$</li>
<li>Scalar multiplication of a matrix $$\pmb{B}&#x3D;\textcolor{red}{d}\cdot \pmb{A}&#x3D;\begin{bmatrix}\textcolor{red}{d}\cdot a_{11} &amp;\cdots &amp;\textcolor{red}{d}\cdot a_{1n}\ \vdots &amp;\ddots &amp;\vdots\ \textcolor{red}{d}\cdot a_{m1} &amp;\cdots &amp;\textcolor{red}{d}\cdot a_{mn}\end{bmatrix}$$</li>
<li>Multiplication of matrices $\pmb{A} \in \mathbb{R}^{m \times n}$ and $\pmb{B} \in \mathbb{R}^{n\times p}$ $$ \pmb{A}\pmb{B}&#x3D;\pmb{C} \in \mathbb{R}^{m\times p},\ \ \ \ c_{ij}&#x3D;\sum_{k&#x3D;1}^na_{ik}b_{kj}$$</li>
<li>Matrix multiplication is <em>associative</em>: $\pmb{A}(\pmb{B}\pmb{C})&#x3D;(\pmb{AB})\pmb{C}$ </li>
<li>Matrix multiplication is <em>distributive</em>: $\pmb A (\pmb B+\pmb C)&#x3D;\pmb{AB}+\pmb{AC}$</li>
<li>Matrix multiplication is <em>NOT communicative</em>: $\pmb{AB} \neq \pmb{BA}$</li>
</ul>
<h4 id="Transpose"><a href="#Transpose" class="headerlink" title="Transpose"></a>Transpose</h4><p>Given a matrix $\pmb A \in \mathbb R^{m\times n}$ , its transpose, written by $\pmb A^T \in \mathbb R^{n\times m}$ , is given by $$(\pmb A^T)<em>{ij}&#x3D;(\pmb A)</em>{ji}$$<br>Some properties</p>
<ul>
<li>$(\pmb{AB})^T&#x3D;\pmb B^T\pmb A^T$</li>
<li>$(\pmb A^T)^T&#x3D;\pmb A$</li>
<li>$(\pmb A+\pmb B)^T&#x3D;\pmb A^T+\pmb B^T$</li>
</ul>
<h4 id="Symmetric-matrix"><a href="#Symmetric-matrix" class="headerlink" title="Symmetric matrix"></a>Symmetric matrix</h4><p>A square matrix is <em>symmetric</em> if $\pmb A &#x3D;\pmb A^T$.</p>
<h4 id="Inverse-of-a-matrix"><a href="#Inverse-of-a-matrix" class="headerlink" title="Inverse of a matrix"></a>Inverse of a matrix</h4><p>For a matrix $\pmb A\in \mathbb R^{n\times n}$ , if there exists a square matrix $\pmb B \in \mathbb R^{n\times n}$ such that $$\pmb{BA}&#x3D;\pmb{AB}&#x3D;\pmb I$$<br>where $\pmb I$ is the $n$-by-$n$ <em>identity matrix</em>, then $\pmb B$ is the <em>inverse</em> of $\pmb A$.</p>
<ul>
<li>The inverse of $\pmb A$ is denoted by $\pmb A^{-1}$ </li>
<li>A matrix is <em>invertible</em> if it is not <em>singular</em>.</li>
</ul>
<p><u>Solving a linear system</u><br>If $\pmb A$ is square nonsingular matrix, then the solution to the linear system $\pmb{AX}&#x3D;\pmb b$ is given by $$\pmb x&#x3D;\pmb A^{-1}\pmb b$$</p>
<h4 id="Semidefinite-matrices"><a href="#Semidefinite-matrices" class="headerlink" title="Semidefinite matrices"></a>Semidefinite matrices</h4><p>A symmetric matrix $\pmb A \in \mathbb S^{n\times n}$ is </p>
<ul>
<li><em>positive semidefinite</em> if $\pmb x^T \pmb{Ax} \geq 0$ for any $\pmb x \in \mathbb R^n$ and $\pmb x \neq \pmb 0$ , denoted by $\pmb A \succcurlyeq 0$ ;</li>
<li><em>positive definite</em> if $\pmb x^T \pmb{Ax} \textgreater 0$ for any $\pmb x \in \mathbb R^n$ and $\pmb x \neq 0$ , denoted by $\pmb A \succ 0$ ;</li>
<li>negative semidefinite if $-\pmb A$ is positive semidefinite;</li>
<li>negative definite if $-\pmb A$ is positive definite;</li>
<li>indefinite if it is neither positive nor negative definite.</li>
</ul>
<h4 id="Back-to-Probability-amp-Statistics"><a href="#Back-to-Probability-amp-Statistics" class="headerlink" title="Back to Probability &amp; Statistics"></a>Back to Probability &amp; Statistics</h4><h5 id="Random-vector"><a href="#Random-vector" class="headerlink" title="Random vector"></a>Random vector</h5><p>A vector of random variables $X_1,X_2,\cdots,X_n$, denoted by $\pmb X&#x3D;[X_1,X_2,\cdots,X_n]^T$ </p>
<ul>
<li>$\mathbb E[X]&#x3D;[\mathbb E[X_1],\mathbb E[X_2],\cdots,\mathbb E[X_n]]^T$</li>
</ul>
<h5 id="Covariance-matrix"><a href="#Covariance-matrix" class="headerlink" title="Covariance matrix"></a>Covariance matrix</h5><p>$$\Sigma &#x3D; \begin{bmatrix} \text{Cov}[X_1,X_1] &amp;\cdots &amp;\text{Cov}[X_1,X_n]\ \vdots &amp;\ddots &amp;\vdots\ \text{Cov}[X_n,X_1] &amp;\cdots &amp;\text{Cov}[X_n,X_n]\end{bmatrix}&#x3D;\mathbb E[(\pmb X -\mathbb E[X])(\pmb X-\mathbb E[\pmb X])^T]$$</p>
<h4 id="Matrix-calculus"><a href="#Matrix-calculus" class="headerlink" title="Matrix calculus"></a>Matrix calculus</h4><p>Consider a function $f:\mathbb R^n \rightarrow \mathbb R$ , the <em>gradient</em> of $f$ is defined as a vector of partial derivatives $$\nabla f(\pmb x)&#x3D;\begin{bmatrix}\cfrac{\partial f(\pmb x)}{\partial x_1}\ \cfrac{\partial f(\pmb x)}{\partial x_2}\ \vdots\ \cfrac{\partial f(\pmb x)}{\partial x_n}\end{bmatrix}$$<br>“direction and rate of fastest <strong>increase</strong>“</p>
<ul>
<li>The direction of fastest increase of the function</li>
<li>The magnitude is the rate of increase</li>
</ul>
<p>Consider a function $f: \mathbb R^n \rightarrow \mathbb R$, the <em>Hessian</em> of $f$ is defined as $$\nabla^2f(\pmb x)&#x3D;\begin{bmatrix}\cfrac{\partial^2f(\pmb x)}{\partial x_1^2} &amp;\cdots &amp;\cfrac{\partial^2f(\pmb x)}{\partial x_1\partial x_n}\ \vdots &amp;\ddots &amp;\vdots\ \cfrac{\partial^2f(\pmb x)}{\partial x_n\partial x_1} &amp;\cdots &amp;\cfrac{\partial^2f(\pmb x)}{\partial x_n^2}\end{bmatrix}$$</p>
<ul>
<li>Hessian is symmetric when $f$ is twice differentiable. $$\cfrac{\partial^2 f(\pmb x)}{\partial x_i\partial x_j}&#x3D;\cfrac{\partial^2f(\pmb x)}{\partial x_j\partial x_i}$$</li>
</ul>
<h3 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h3><h4 id="What-is-optimization"><a href="#What-is-optimization" class="headerlink" title="What is optimization?"></a>What is optimization?</h4><p>Finding the minimizer of a function subject to constraints:<br>$$\begin{align}<br>\text{minimize}_{\pmb x} \ \ \ \ &amp;f(\pmb x) \<br>s.t.\ \ \ \ &amp;f_i(\pmb x)\leq 0,i&#x3D;1,2,\cdots, k;\<br>&amp;h_j(\pmb x)&#x3D;0,j&#x3D;1,2,\cdots,l.<br>\end{align}$$</p>
<ul>
<li>Mean-variance analysis</li>
<li>Transportation problems</li>
<li>Facility location</li>
<li>Linear regression</li>
<li>Logistic regression</li>
<li>Support vector machine</li>
<li>Neural networks</li>
</ul>
<h4 id="Local-minima-and-global-minima"><a href="#Local-minima-and-global-minima" class="headerlink" title="Local minima and global minima"></a>Local minima and global minima</h4><ul>
<li>Local minima is the solution that optimal within a neighboring set</li>
<li>Global minima is the optimal solution among all possible solutions<br><img src="/pic/379ac1b116f3c5612b0e6a1f3df25ea.png"></li>
</ul>
<h4 id="Convex-set"><a href="#Convex-set" class="headerlink" title="Convex set"></a>Convex set</h4><p>A set $C\in \mathbb R^n$ is <em>convex</em> if for $\pmb x,\pmb y\in C$ and any $\alpha\in [0,1]$, $$\alpha \pmb x+(1-\alpha)\pmb y \in C$$<img src="/pic/b885ffb38cf90c077ad79abb079e005.png"></p>
<p>Examples: $\mathbb R^n$ , norm ball {$\pmb x: ||\pmb x|| \leq r$} for a given $r$ , intersection of convex sets</p>
<h4 id="Convex-Concave-function"><a href="#Convex-Concave-function" class="headerlink" title="Convex (Concave) function"></a>Convex (Concave) function</h4><p>A function $f:\mathbb R^n \rightarrow \mathbb R$ is convex (concave) if for $\pmb x,\pmb y \in \text{dom}(f)$ and any $\alpha \in [0,1]$ , $$f(\alpha \pmb x+(1-\alpha)\pmb y)\leq(\geq) \alpha f(\pmb x)+(1-\alpha)f(\pmb y)$$<img src="/pic/57c1cdf60aceade4f79afcdcf5781c5.png"></p>
<h4 id="First-order-convexity-condition"><a href="#First-order-convexity-condition" class="headerlink" title="First-order convexity condition"></a>First-order convexity condition</h4><p>Suppose a function $f:\mathbb R^n \rightarrow \mathbb R$ is differentiable. Then $f$ is convex if and only if for all $\pmb x,\pmb y \in \text{dom}(f)$ $$f(\pmb y) \geq f(\pmb x) + \nabla f(\pmb x)^T(\pmb y-\pmb x)$$<img src="/pic/b9432d6edc99c82146c5ca340b6fd65.png"></p>
<h4 id="Second-order-convexity-condition"><a href="#Second-order-convexity-condition" class="headerlink" title="Second-order convexity condition"></a>Second-order convexity condition</h4><p>Suppose a function $f:\mathbb R^n \rightarrow \mathbb R$ is twice differentiable. Then $f$ is convex if and only if for all $\pmb x \in \text{dom}(f)$ $$\nabla^2f(\pmb x)\succcurlyeq 0$$<img src="/pic/8c43075b2094ec2db8c526f1ea28d14.png"></p>
<h4 id="Examples-of-convex-functions"><a href="#Examples-of-convex-functions" class="headerlink" title="Examples of convex functions"></a>Examples of convex functions</h4><ul>
<li>Exponential function: $e^{ax}$</li>
<li>Logarithmic function: $\log(x)$ is concave</li>
<li>Affine function: $\pmb a^T\pmb x+b$ is a convex and concave</li>
<li>Least square loss: $||\pmb y-\pmb{X\beta}||_2^2$</li>
<li>$f_1(x)$ is convex for $x\in \text{dom}(f_1)$ and $f_2(x)$ is convex for $x\in \text{dom}(f_2)$ , then $f_1+f_2$ is convex for $x\in \text{dom}(f_1) \cap \text{dom}(f_2)$</li>
</ul>
<h4 id="Convex-optimization-problem"><a href="#Convex-optimization-problem" class="headerlink" title="Convex optimization problem"></a>Convex optimization problem</h4><p>An optimization problem is convex if its objective is a convex function, the inequality constraints $f_j$ are convex, and the equality constraints $h_j$ are affine.<br>$$\begin{align}<br>\text{minimize}_{\pmb x} \ \ \ \ &amp;f(\pmb x)\<br>s.t. \ \ \ \ &amp;f_i(\pmb x)\leq 0,i&#x3D;1,2,\cdots,k; \<br>&amp;h_j(\pmb x)&#x3D;0,j&#x3D;1,2,\cdots,l.<br>\end{align}$$</p>
<h4 id="It’s-nice-to-be-convex"><a href="#It’s-nice-to-be-convex" class="headerlink" title="It’s nice to be convex!"></a>It’s nice to be convex!</h4><ul>
<li>$\nabla f(\pmb x)&#x3D;0$ if and only if $\pmb x$ is a global minimizer of $f(\pmb x)$ .</li>
<li>If $\pmb x$ is a local minimizer of a convex optimization problem, it is a global minimizer.</li>
</ul>
<h4 id="Optimization-methods"><a href="#Optimization-methods" class="headerlink" title="Optimization methods"></a>Optimization methods</h4><ul>
<li>Gradient descent</li>
<li>Newton’s method</li>
<li>Coordinate descent</li>
<li>Lagrangian method</li>
</ul>

      
    </div>
    <div class="article-footer">
      <blockquote class="mt-2x">
  <ul class="post-copyright list-unstyled">
    
    <li class="post-copyright-link hidden-xs">
      <strong>本文链接：</strong>
      <a href="http://hiryan23.github.io/2023/02/17/Machine%20Learning/" title="机器学习-课程笔记" target="_blank" rel="external">http://hiryan23.github.io/2023/02/17/Machine Learning/</a>
    </li>
    
    <li class="post-copyright-license">
      <strong>版权声明： </strong> 本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by/4.0/deed.zh" target="_blank" rel="external">CC BY 4.0 CN协议</a> 许可协议。转载请注明出处！
    </li>
  </ul>
</blockquote>


<div class="panel panel-default panel-badger">
  <div class="panel-body">
    <figure class="media">
      <div class="media-left">
        <a href="" target="_blank" class="img-burn thumb-sm visible-lg">
          <img src="/images/avatar.jpg" class="img-rounded w-full" alt="">
        </a>
      </div>
      <div class="media-body">
        <h3 class="media-heading"><a href="" target="_blank"><span class="text-dark">Ruiyang He</span><small class="ml-1x">上海交通大学 本科生</small></a></h3>
        <div>生活不止眼前的苟且。</div>
      </div>
    </figure>
  </div>
</div>


    </div>
  </article>
  
    
  <section id="comments">
  	
      <div id="vcomments"></div>
    
  </section>


  
</div>

  <nav class="bar bar-footer clearfix" data-stick-bottom>
  <div class="bar-inner">
    
      <ul class="pager pull-left">
        
          <li class="prev">
            <a href="/2023/02/19/%E5%AF%B9chatgpt%E7%9A%84%E6%AC%A2%E5%91%BC%E6%98%AF%E4%BA%BA%E5%AF%B9%E5%BC%82%E5%8C%96%E7%9A%84%E5%8F%8D%E6%8A%97%E2%80%94%E2%80%94%E8%AE%BAai%E4%BB%A3%E5%86%99%E8%AE%BA%E6%96%87%E7%9A%84%E8%A7%A3%E6%94%BE%E6%80%A7%E4%B8%8E%E5%BC%80%E6%94%BE%E6%80%A7/" title="对chatgpt的欢呼是人对异化的反抗——论ai代写论文的解放性与开放性"><i
                class="icon icon-angle-left" aria-hidden="true"></i><span>&nbsp;&nbsp;上一篇</span></a>
          </li>
          
            
              <li class="next">
                <a href="/2023/02/17/%E5%8D%9A%E5%BC%88%E8%AE%BA/" title="博弈论-课程笔记"><span>
                    下一篇&nbsp;&nbsp;
                  </span><i class="icon icon-angle-right" aria-hidden="true"></i></a>
              </li>
              
                
                  <li class="toggle-toc">
                    <a class="toggle-btn " data-toggle="collapse"
                      href="#collapseToc" aria-expanded="false" title="文章目录" role="button">
                      <span>[&nbsp;</span><span>
                        文章目录
                      </span>
                      <i class="text-collapsed icon icon-anchor"></i>
                      <i class="text-in icon icon-close"></i>
                      <span>]</span>
                    </a>
                  </li>
                  
      </ul>
      
        

            <div class="bar-right">
              
                <div class="share-component" data-sites="qq,wechat"
                  data-mobile-sites="qq,wechat"></div>
                
            </div>
  </div>
</nav>
  


</main>

  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
<footer class="footer" itemscope itemtype="http://schema.org/WPFooter">
    
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/hiryan23" target="_blank" title="Github" data-toggle=tooltip data-placement=top><i class="icon icon-github"></i></a></li>
        
    </ul>

        <div class="copyright">
            
                &copy; 2023
                    Ruiyang He
                        

                            <div class="publishby">
                                <span id="busuanzi_container_site_pv">
                                    <!--点击<span id="busuanzi_value_site_pv" style="font-family:Courier"></span>次，
                                    -->
                                    访客<span id="busuanzi_value_site_uv" style="font-family:Courier"></span>人
                                </span>
                            </div>

                            <!--
        <div class="publishby">
            Theme by
            <a href="https://github.com/cofess" target="_blank"> cofess </a>
            base on
            <a href="https://github.com/cofess/hexo-theme-pure" target="_blank">pure</a>.
        </div>
        -->
        </div>
</footer>
  <script src="//cdn.jsdelivr.net/npm/jquery@1.12.4/dist/jquery.min.js"></script>
<script>
   window.jQuery || document.write('<script src="js/jquery.min.js"><\/script>')
</script>

<script src="/js/plugin.min.js"></script>

   
<script src="/js/application.js"></script>

      
    <script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>



         
                  
                           
                              
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>



                                 
                                    
                                       
    
  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/valine"></script>
  <script type="text/javascript">
  var GUEST = ['nick', 'mail', 'link'];
  var meta = 'nick,mail,link';
  meta = meta.split(',').filter(function(item) {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#vcomments',
    verify: false,
    notify: false,
    appId: 'kuf03HfUPLpIZjgOwQwJ4d7f-9Nh9j0Va',
    appKey: 'dIdmyF1QYnqtOiB5b9grGYyf',
    placeholder: '不怀疑不能见真理',
    avatar: 'mm',
    meta: meta,
    pageSize: '10' || 10,
    visitor: false
  });
  </script>

     

                                          
                                             

                                                



                                                   <div id="go-top"></div>
                                                   <style type="text/css">
                                                      #go-top {
                                                         width: 40px;
                                                         height: 36px;
                                                         background-color: #5a7db1;
                                                         position: relative;
                                                         border-radius: 2px;
                                                         position: fixed;
                                                         right: 10px;
                                                         bottom: 60px;
                                                         cursor: pointer;
                                                         display: none;
                                                      }

                                                      #go-top:after {
                                                         content: " ";
                                                         position: absolute;
                                                         left: 14px;
                                                         top: 14px;
                                                         border-top: 2px solid #fff;
                                                         border-right: 2px solid #fff;
                                                         width: 12px;
                                                         height: 12px;
                                                         transform: rotate(-45deg);
                                                      }

                                                      #go-top:hover {
                                                         background-color: #1A2433;
                                                      }
                                                   </style>
                                                   <script>
                                                      $(function () {
                                                         var top = $("#go-top");
                                                         $(window).scroll(function () {
                                                            ($(window).scrollTop() > 300) ? top.show(300) : top.hide(200);
                                                            $("#go-top").click(function () {
                                                               $('body,html').animate({ scrollTop: 0 });
                                                               return false();
                                                            })
                                                         });
                                                      });
                                                   </script>
</body>
</html>